{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321a6b29-115d-4780-b264-334e8b2fe797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, roc_auc_score, f1_score, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import issparse\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff0de57-2051-4072-868d-deb226be0668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in input files\n",
    "real_prot = pd.read_csv('./measured_proteomics_random.csv')\n",
    "syn_prot = pd.read_csv('./RABIT_proteomics_random.csv')\n",
    "ehr_rep = pd.read_csv('ehr_representations_random.csv')\n",
    "ehr_rep.drop('labeling_time', axis=1, inplace=True)\n",
    "master_labels = pd.read_csv('./master_labels_random.csv') ## CHANGED LABELS TO MATCH AGING CLOCK\n",
    "pred_time = pd.read_csv('./pred_time_random.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104a5b3a-c685-4971-a110-24d59304f61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat to match column names\n",
    "real_prot.rename(columns={'eid': 'patient_ids'}, inplace=True)\n",
    "syn_prot.rename(columns={'sample_eid': 'patient_ids'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4800c41c-4e2b-41b7-8f03-8a33db98d663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join pred times to master_labels\n",
    "label_final = pd.merge(pred_time[['patient_id', 'prediction_time']], master_labels, left_on='patient_id', right_on='person_id', how='inner')\n",
    "label_final.drop(columns=['person_id'], inplace=True)\n",
    "label_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5929103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ehr+RABIT_proteomics and ehr+measured_proteomics dataframes\n",
    "motor_real_prot = ehr_rep.merge(real_prot, on=\"patient_ids\", how=\"inner\")\n",
    "motor_syn_prot = ehr_rep.merge(syn_prot, on=\"patient_ids\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c03833f-c8ca-4b4b-a8ba-23c400e9eae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(df, timeint, colnames):\n",
    "    result_df = pd.DataFrame()\n",
    "    result_df['patient_id'] = df['patient_id']\n",
    "    \n",
    "    # strip time from prediction_time and convert to datetime\n",
    "    df['prediction_date'] = pd.to_datetime(df['prediction_time']).dt.date\n",
    "    \n",
    "    # add timeint to prediction_time to create horizontime\n",
    "    df['horizontime'] = df['prediction_date'] + timedelta(days=timeint)\n",
    "    \n",
    "    # loop over each column in colnames\n",
    "    for col in colnames:\n",
    "        result_df[col] = None  \n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce').dt.date\n",
    "        \n",
    "        # remove patients with diagnosis prior to prediction time. label 1 if diagnosis is within 5 years of prediction time, else 0.\n",
    "        result_df[col] = df.apply(\n",
    "            lambda row: 'remove' if pd.notnull(row[col]) and row[col] < row['prediction_date']\n",
    "            else 1 if pd.notnull(row[col]) and row['prediction_date'] <= row[col] <= row['horizontime']\n",
    "            else 0, axis=1\n",
    "        )\n",
    "\n",
    "    result_df.rename(columns={'patient_id': 'patient_ids'}, inplace=True)\n",
    "    return result_df\n",
    "\n",
    "colnames = [col for col in master_labels.columns if col not in ['person_id']]\n",
    "timeint = 1827  # 5 years\n",
    "\n",
    "input_labels = process_dataframe(label_final, timeint, colnames)\n",
    "input_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9609a609-2a15-4d1e-9e3b-8d126d513691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see number of cases\n",
    "count_ones = input_labels[input_labels.columns].apply(lambda col: (col == 1).sum())\n",
    "count_remove = input_labels[input_labels.columns].apply(lambda col: (col == 'remove').sum())\n",
    "\n",
    "print(count_ones,'\\n')\n",
    "print(count_remove)\n",
    "\n",
    "# remove columns where count_ones is 0 (excluding 'patient_ids')\n",
    "columns_to_remove = count_ones[count_ones == 0].index.tolist()\n",
    "if 'patient_ids' in columns_to_remove:\n",
    "    columns_to_remove.remove('patient_ids')\n",
    "\n",
    "# drop the columns from input_labels\n",
    "input_labels = input_labels.drop(columns=columns_to_remove)\n",
    "\n",
    "# return the updated input_labels\n",
    "input_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9918c21-d9cb-4dc0-9631-d28302460558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_task_cv_xgboost_dense(input_data, label_data, output_dir, timehorizon, positive_ratio=0.25):\n",
    "    # create the timehorizon subdirectory within output_dir\n",
    "    timehorizon_dir = os.path.join(output_dir, timehorizon)\n",
    "    os.makedirs(timehorizon_dir, exist_ok=True)\n",
    "\n",
    "    # merge the input and label dataframes on 'patient_ids'\n",
    "    df_merged = input_data.merge(label_data, on='patient_ids')\n",
    "    patient_ids = df_merged['patient_ids']\n",
    "    results = []\n",
    "    predvalues = []\n",
    "    featimp_dict = {}  \n",
    "    \n",
    "    # random number generation with fixed seed\n",
    "    rng = np.random.RandomState(42)\n",
    "\n",
    "    # loop through each disease in label_data (excluding 'patient_ids')\n",
    "    for task in tqdm(label_data.columns.drop('patient_ids'), desc=\"Tasks\"):\n",
    "\n",
    "        # create a subdirectory for the disease\n",
    "        task_dir = os.path.join(timehorizon_dir, task.replace(\" \", \"_\"))\n",
    "        os.makedirs(task_dir, exist_ok=True)\n",
    "\n",
    "        # remove rows where label is \"remove\" for the current disease\n",
    "        df_task = df_merged[df_merged[task] != \"remove\"]\n",
    "        X = df_task.drop(columns=['patient_ids'] + label_data.columns.tolist())  # Features\n",
    "        y = df_task[task].astype(int)  # Current task label, converted to integer\n",
    "\n",
    "        # get filtered patient IDs\n",
    "        task_patient_ids = df_task['patient_ids']\n",
    "\n",
    "        # 3 fold CV\n",
    "        skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        all_y_true = []\n",
    "        all_y_pred = []\n",
    "        all_y_pred_proba = []\n",
    "        featimp_per_task = []\n",
    "\n",
    "        for fold_idx, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "            # data split\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            test_patient_ids = task_patient_ids.iloc[test_index]\n",
    "\n",
    "            # Undersample negative class to achieve 10% minimum prevalence\n",
    "            pos_mask = y_train == 1\n",
    "            neg_mask = y_train == 0\n",
    "            n_pos = pos_mask.sum()\n",
    "            n_neg = neg_mask.sum()\n",
    "\n",
    "            if n_pos > 0 and (n_pos / len(y_train)) < positive_ratio:\n",
    "                desired_neg = int(((1 / positive_ratio) - 1) * n_pos)\n",
    "                if n_neg > desired_neg:\n",
    "                    # randomly select a subset of negatives with reproducibility\n",
    "                    selected_neg_indices = rng.choice(y_train[neg_mask].index, size=desired_neg, replace=False)\n",
    "                    # combine with all positive indices\n",
    "                    new_train_indices = y_train[pos_mask].index.union(pd.Index(selected_neg_indices))\n",
    "                    X_train = X_train.loc[new_train_indices]\n",
    "                    y_train = y_train.loc[new_train_indices]\n",
    "            # --------------------------------------------------------------------\n",
    "\n",
    "            # initialize XGBoost model\n",
    "            xgb_model = xgb.XGBClassifier(eval_metric='logloss', n_jobs=12)\n",
    "\n",
    "            # train\n",
    "            xgb_model.fit(X_train, y_train)\n",
    "\n",
    "            # save model for fold\n",
    "            model_filename = os.path.join(task_dir, f\"{task.replace(' ', '_')}_fold_{fold_idx}.joblib\")\n",
    "            joblib.dump(xgb_model, model_filename)\n",
    "\n",
    "            # evaluate on test set\n",
    "            y_pred = xgb_model.predict(X_test)\n",
    "            y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]  # Get probabilities for ROC AUC and AUPRC\n",
    "\n",
    "            all_y_true.extend(y_test)\n",
    "            all_y_pred.extend(y_pred)\n",
    "            all_y_pred_proba.extend(y_pred_proba)\n",
    "\n",
    "            for pid, true_label, pred_prob, pred_label in zip(test_patient_ids, y_test, y_pred_proba, y_pred):\n",
    "                predvalues.append({\n",
    "                    'patient_ids': pid,\n",
    "                    'task': task,\n",
    "                    'true_label': true_label,\n",
    "                    'predicted_probability': pred_prob,\n",
    "                    'predicted_label': pred_label\n",
    "                })\n",
    "\n",
    "            # get feature importance (gain) for the current fold\n",
    "            featimp_per_task.append(xgb_model.get_booster().get_score(importance_type='gain'))\n",
    "\n",
    "        # average feature importance across folds for the current task\n",
    "        avg_featimp = pd.DataFrame(featimp_per_task).mean(axis=0).to_dict()\n",
    "        featimp_dict[task] = avg_featimp\n",
    "\n",
    "        # convert the lists to NumPy arrays for metric calculations\n",
    "        all_y_true = np.array(all_y_true)\n",
    "        all_y_pred = np.array(all_y_pred)\n",
    "        all_y_pred_proba = np.array(all_y_pred_proba)\n",
    "\n",
    "        # calculate overall metrics\n",
    "        accuracy = accuracy_score(all_y_true, all_y_pred)\n",
    "        roc_auc = roc_auc_score(all_y_true, all_y_pred_proba)\n",
    "        auprc = average_precision_score(all_y_true, all_y_pred_proba)\n",
    "        prevalence = np.mean(all_y_true)\n",
    "\n",
    "        # store the results\n",
    "        results.append({\n",
    "            'task': task,\n",
    "            'accuracy': accuracy,\n",
    "            'roc_auc': roc_auc,\n",
    "            'auprc': auprc,\n",
    "            'prevalence': prevalence\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    predvalues_df = pd.DataFrame(predvalues)\n",
    "\n",
    "    featimp_df = pd.DataFrame(featimp_dict).T.fillna(0)  # Fill missing values with 0\n",
    "\n",
    "    return results_df, predvalues_df, featimp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bc669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeperiod = '5yrs'\n",
    "pos_percent = 0.10 # What percentage should be positive cases when subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b358a84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdir = '/path/to/outputdir'\n",
    "modeloutputdir_realprot = '/path/to/modeldir/task_models_measuredprot'\n",
    "modeloutputdir_synprot = '/path/to/modeldir/task_models_rabitprot'\n",
    "modeloutputdir_motorrep = '/path/to/modeldir/task_models_ehrrep'\n",
    "modeloutputdir_motorrealprot = '/path/to/modeldir/task_models_ehr_measuredprot'\n",
    "modeloutputdir_motorsynprot = '/path/to/modeldir/task_models_ehr_rabitprot'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99ac244",
   "metadata": {},
   "source": [
    "# Train disease onset prediction models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ed691e-174b-4272-983e-0af4d3be0d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_prot_results, real_prot_predvalues, real_prot_featimp = multi_task_cv_xgboost_dense(real_prot, input_labels, modeloutputdir_realprot, timeperiod, positive_ratio=pos_percent)\n",
    "real_prot_results.to_csv(f\"/{outputdir}/real_prot_{timeperiod}_results.csv\", index=False)\n",
    "real_prot_predvalues.to_csv(f\"/{outputdir}/real_prot_{timeperiod}_predvalues.csv\", index=False)\n",
    "real_prot_featimp.to_csv(f\"/{outputdir}/real_prot_{timeperiod}_featimp.csv\")\n",
    "real_prot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2c8996",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_prot_results, syn_prot_predvalues, syn_featimp = multi_task_cv_xgboost_dense(syn_prot, input_labels, modeloutputdir_synprot, timeperiod, positive_ratio=pos_percent)\n",
    "syn_prot_results.to_csv(f\"/{outputdir}/syn_prot_{timeperiod}_results.csv\", index=False)\n",
    "syn_prot_predvalues.to_csv(f\"/{outputdir}/syn_prot_{timeperiod}_predvalues.csv\", index=False)\n",
    "syn_featimp.to_csv(f\"/{outputdir}/syn_prot_{timeperiod}_featimp.csv\")\n",
    "syn_prot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c15bb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_rep_results, ehr_rep_predvalues, ehr_rep_featimp = multi_task_cv_xgboost_dense(ehr_rep, input_labels, modeloutputdir_motorrep, timeperiod, positive_ratio=pos_percent)\n",
    "ehr_rep_results.to_csv(f\"/{outputdir}/ehr_rep_{timeperiod}_results.csv\", index=False)\n",
    "ehr_rep_predvalues.to_csv(f\"/{outputdir}/ehr_rep_{timeperiod}_predvalues.csv\", index=False)\n",
    "ehr_rep_featimp.to_csv(f\"/{outputdir}/ehr_rep_{timeperiod}_featimp.csv\")\n",
    "ehr_rep_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0c4be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "motor_realprot_results, motor_realprot_predvalues, motor_realprot_featimp = multi_task_cv_xgboost_dense(motor_real_prot, input_labels, modeloutputdir_motorrealprot, timeperiod, positive_ratio=pos_percent)\n",
    "motor_realprot_results.to_csv(f\"/{outputdir}/motor_realprot_{timeperiod}_results.csv\", index=False)\n",
    "motor_realprot_predvalues.to_csv(f\"/{outputdir}/motor_realprot_{timeperiod}_predvalues.csv\", index=False)\n",
    "motor_realprot_featimp.to_csv(f\"/{outputdir}/motor_realprot_{timeperiod}_featimp.csv\")\n",
    "motor_realprot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9610e5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "motor_synprot_results, motor_synprot_predvalues, motor_synprot_featimp = multi_task_cv_xgboost_dense(motor_syn_prot, input_labels, modeloutputdir_motorsynprot, timeperiod, positive_ratio=pos_percent)\n",
    "motor_synprot_results.to_csv(f\"/{outputdir}/motor_synprot_{timeperiod}_results.csv\", index=False)\n",
    "motor_synprot_predvalues.to_csv(f\"/{outputdir}/motor_synprot_{timeperiod}_predvalues.csv\", index=False)\n",
    "motor_synprot_featimp.to_csv(f\"/{outputdir}/motor_synprot_{timeperiod}_featimp.csv\")\n",
    "motor_synprot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c27b476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bed5c1b-20e7-4223-af9f-4f023724b7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "davidpython_updated",
   "language": "python",
   "name": "davidpython_updated"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
