{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2367cc53-cff9-40a3-9091-10ee9dc73c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import io\n",
    "import os\n",
    "import warnings\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zstandard as zstd\n",
    "from scipy.stats import mannwhitneyu\n",
    "from tqdm import tqdm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    average_precision_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2360184c-3d00-427b-a3df-364d9e7cba35",
   "metadata": {},
   "source": [
    "# external et al paper: https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010204"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dae0de0-ea70-4796-b481-6854c4537c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_df = pd.read_csv('/path/to/omop/concept.csv')\n",
    "visit_occurrence_df = pd.read_csv('/path/to/omop/visit_occurrence.csv')\n",
    "drug_df_sub = pd.read_csv('/path/to/omop/drug_exposure.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d7a04a-5138-47e1-9e46-d34baead7cde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get all concept ids for anti-tnf therapy\n",
    "def filter_by_concept_name(\n",
    "    df: pd.DataFrame,\n",
    "    substrings: Union[str, List[str]],\n",
    "    name_col: str = \"concept_name\",\n",
    "    id_col: str = \"concept_id\"\n",
    ") -> Tuple[pd.DataFrame, List[Any]]:\n",
    "\n",
    "    if isinstance(substrings, str):\n",
    "        substrings = [substrings]\n",
    "    if not substrings:\n",
    "        print(\"No substrings provided; returning empty result.\")\n",
    "        return df.iloc[0:0].copy(), []\n",
    "\n",
    "    mask = pd.Series(False, index=df.index)\n",
    "    for sub in substrings:\n",
    "        mask |= df[name_col].str.contains(sub, case=False, na=False)\n",
    "\n",
    "    # drop duplicate rows\n",
    "    filtered_df = df.loc[mask].drop_duplicates().copy()\n",
    "\n",
    "    ids = filtered_df[id_col].unique().tolist()\n",
    "\n",
    "    print(f\"Found {len(filtered_df)} unique rows matching {substrings!r} in '{name_col}'.\")\n",
    "    print(f\"Unique {id_col} values: {ids}\")\n",
    "\n",
    "    return filtered_df, ids\n",
    "\n",
    "drug_names = ['adalimumab', 'etanercept', 'infliximab', 'certolizumab pegol', 'golimumab']\n",
    "filtered_concepts, drug_ids = filter_by_concept_name(concept_df, drug_names)\n",
    "filtered_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffead19-fbf6-41ef-b60f-30b97c7052a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# subset drug dataframe to include only anti-tnf drugs\n",
    "def filter_by_drug_concept_id(\n",
    "    df: pd.DataFrame,\n",
    "    concept_ids: List[int],\n",
    "    column: str = \"drug_concept_id\"\n",
    ") -> pd.DataFrame:\n",
    "    filtered = df[df[column].isin(concept_ids)].copy()\n",
    "    counts = filtered[column].value_counts().reindex(concept_ids, fill_value=0)\n",
    "    \n",
    "    # Print the counts\n",
    "    print(\"Row counts by drug_concept_id:\")\n",
    "    for cid, cnt in counts.items():\n",
    "        print(f\"  {cid}: {cnt}\")\n",
    "    \n",
    "    return filtered\n",
    "\n",
    "\n",
    "filtered_drugs = filter_by_drug_concept_id(drug_df_sub, drug_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67c41e1-db3c-4e42-83dd-fb09be7dc6fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# organize patient information of all patients who recieved anti-tnf\n",
    "def create_person_drug_visit_dict(\n",
    "    drugsub: pd.DataFrame,\n",
    "    visdf: pd.DataFrame\n",
    ") -> Dict[Any, Dict[str, List[pd.Timestamp]]]:\n",
    "\n",
    "    drug = drugsub.copy()\n",
    "    visits = visdf.copy()\n",
    "    \n",
    "    drug['drug_exposure_start_DATE'] = pd.to_datetime(\n",
    "        drug['drug_exposure_start_DATE'], errors='coerce'\n",
    "    )\n",
    "    visits['visit_start_DATE'] = pd.to_datetime(\n",
    "        visits['visit_start_DATE'], errors='coerce'\n",
    "    )\n",
    "    \n",
    "    summary_dict: Dict[Any, Dict[str, List[pd.Timestamp]]] = {}\n",
    "    \n",
    "    for pid in drug['person_id'].unique():\n",
    "        person_visits = visits.loc[\n",
    "            visits['person_id'] == pid, 'visit_start_DATE'\n",
    "        ].dropna().sort_values()\n",
    "        visit_list: List[pd.Timestamp] = person_visits.tolist()\n",
    "        \n",
    "        person_drugs = drug.loc[\n",
    "            drug['person_id'] == pid, 'drug_exposure_start_DATE'\n",
    "        ].dropna().sort_values()\n",
    "        drug_list: List[pd.Timestamp] = person_drugs.tolist()\n",
    "        \n",
    "        summary_dict[pid] = {\n",
    "            'all_visits': visit_list,\n",
    "            'drug_administrations': drug_list\n",
    "        }\n",
    "    \n",
    "    return summary_dict\n",
    "\n",
    "\n",
    "summary_dict = create_person_drug_visit_dict(filtered_drugs, visit_occurrence_df)\n",
    "summary_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19f2025-0c77-406a-b407-0801748686bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dictionary to dataframe for easier downstream processing\n",
    "def summary_dict_to_dataframe(\n",
    "    summary_dict: Dict[Any, Dict[str, List[pd.Timestamp]]]\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    records = []\n",
    "    for pid, data in summary_dict.items():\n",
    "        visits = data.get(\"all_visits\", [])\n",
    "        drugs = data.get(\"drug_administrations\", [])\n",
    "\n",
    "        # Defaults if there are no drug administrations\n",
    "        if drugs:\n",
    "            first_drug = drugs[0]\n",
    "            last_drug = drugs[-1]\n",
    "            visits_before = sum(1 for v in visits if v < first_drug)\n",
    "            visits_after = sum(1 for v in visits if v > last_drug)\n",
    "        else:\n",
    "            visits_before = 0\n",
    "            visits_after = 0\n",
    "\n",
    "        records.append({\n",
    "            \"person_id\": pid,\n",
    "            \"visits_before_first_drug\": visits_before,\n",
    "            \"visits_after_last_drug\": visits_after,\n",
    "            \"total_drug_administrations\": len(drugs)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame.from_records(records)\n",
    "\n",
    "\n",
    "drug_admin_stat_df = summary_dict_to_dataframe(summary_dict)\n",
    "drug_admin_stat_df_summary = pd.merge(drug_admin_stat_df, rabit_metadata, on='person_id', how='inner')\n",
    "drug_admin_stat_df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc534888-b0a6-4724-8ee5-e719928aa194",
   "metadata": {},
   "source": [
    "## Create label for ehr representation generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48da4a60-2ea5-47db-90b1-937f9da86123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a lookup of each patient’s earliest drug date (or NaT if none)\n",
    "earliest_drug = {\n",
    "    pid: drugs[0] if drugs else pd.NaT\n",
    "    for pid, data in summary_dict.items()\n",
    "    for drugs in [data.get('drug_administrations', [])]\n",
    "}\n",
    "\n",
    "rabit_labels = pd.DataFrame()\n",
    "\n",
    "rabit_labels['patient_id'] = drug_admin_stat_df_summary['person_id']\n",
    "rabit_labels['prediction_time'] = (\n",
    "    rabit_labels['patient_id']\n",
    "    .map(earliest_drug)                     # lookup earliest drug timestamp\n",
    "    .dt.floor('T')                          # drop seconds\n",
    "    .dt.strftime('%Y-%m-%d %H:%M:%S')       # format as string\n",
    ")\n",
    "rabit_labels['label_type'] = 'boolean'\n",
    "rabit_labels['value'] = True\n",
    "\n",
    "rabit_labels.to_csv(\n",
    "    '/path/to/label/directory',\n",
    "    index=False\n",
    ")\n",
    "rabit_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43df1df-3223-4080-a3cb-5a3129e4c840",
   "metadata": {},
   "source": [
    "# Create responder/nonresponder labels\n",
    "\n",
    "### if a timestamp for a visit (with no anti-tnf record) exists at least 12 months after latest record of anti-tnf record, patient is marked as a non-responder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44da6410-8f69-4eb7-a734-de6ef945d22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def responder_summary_df(\n",
    "    summary_dict: Dict[Any, Dict[str, List[pd.Timestamp]]], deltamon=6\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    records = []\n",
    "    for pid, data in summary_dict.items():\n",
    "        visits = data.get('all_visits', [])\n",
    "        drugs = data.get('drug_administrations', [])\n",
    "        \n",
    "        responder = True\n",
    "        if drugs and visits:\n",
    "            latest_drug = drugs[-1]\n",
    "            cutoff = latest_drug + pd.DateOffset(months=deltamon)\n",
    "            # if any visit ≥ cutoff, mark as non-responder\n",
    "            if any(v >= cutoff for v in visits):\n",
    "                responder = False\n",
    "        \n",
    "        records.append({\n",
    "            'person_id': pid,\n",
    "            'responder': responder\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    counts = df['responder'].value_counts()\n",
    "    n_true = counts.get(True, 0)\n",
    "    n_false = counts.get(False, 0)\n",
    "    \n",
    "    print(f\"Responders (True): {n_true}\")\n",
    "    print(f\"Non-responders (False): {n_false}\")\n",
    "    return df\n",
    "\n",
    "responder_df = responder_summary_df(summary_dict, deltamon=12)\n",
    "responder_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abecb3c6-9e8e-4861-b53c-0dff8fb13b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset of those who received anti-tnf for patients who had diagnosed RA\n",
    "diag_labels = pd.read_csv('/path/to/omop/condition_occurrence.csv')\n",
    "# extract patient_ids and time of diagnosis of RA (defined as ICD10 code: M05,M06)\n",
    "## filter for patients who had RA diagnosis on or before anti-tnf treatment start date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c223fe-b4a3-425c-ad3e-f5cc69731817",
   "metadata": {},
   "source": [
    "## Generate RABIT proteomics for final cohort of patients at the time of anti-tnf treatment beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f135cdd-3a1c-4530-accd-0a732e74bd42",
   "metadata": {},
   "source": [
    "## Subset RABIT proteomics panel to include only the 344 proteins that overlap with external dataset for fair comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaff266-1e90-430c-b1ba-f2dca24b5426",
   "metadata": {},
   "source": [
    "# Train RABIT-trained and External-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e7ec82-b881-4274-a187-393aa405e3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_enet_cv(\n",
    "    df: pd.DataFrame,\n",
    "    id_col: str,\n",
    "    label_col: str,\n",
    "    output_dir: str,\n",
    "    outer_splits: int = 5,\n",
    "    inner_splits: int = 10,\n",
    "    random_state: int = 42,\n",
    "    l1_ratio: float = 0.9,\n",
    "):\n",
    "   \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    X  = df.drop(columns=[id_col, label_col])\n",
    "    y  = df[label_col]\n",
    "    ids = df[id_col]\n",
    "\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            penalty=\"elasticnet\",\n",
    "            solver=\"saga\",\n",
    "            l1_ratio=l1_ratio,\n",
    "            max_iter=20_000,\n",
    "            random_state=random_state,\n",
    "            n_jobs=-1,\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    # hyperparameter searching\n",
    "    param_grid = {\n",
    "        \"clf__C\": 10 ** np.linspace(-4, 4, 15),\n",
    "        \"clf__l1_ratio\": np.linspace(0.0, 1.0, 6),\n",
    "    }\n",
    "\n",
    "    outer_cv = StratifiedKFold(\n",
    "        n_splits=outer_splits, shuffle=True, random_state=random_state\n",
    "    )\n",
    "\n",
    "    metrics_records, param_records, coef_records, oof_records = [], [], [], []\n",
    "\n",
    "    fpr_grid     = np.linspace(0.0, 1.0, 101)\n",
    "    recall_grid  = np.linspace(0.0, 1.0, 101)\n",
    "    tpr_rows, prec_rows = [], []          # will become (folds × 101) arrays\n",
    "\n",
    "    # outer fold cross validation\n",
    "    for fold, (train_idx, test_idx) in enumerate(\n",
    "        tqdm(list(outer_cv.split(X, y)), desc=\"Outer CV folds\"), start=1\n",
    "    ):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        inner_cv = StratifiedKFold(\n",
    "            n_splits=inner_splits, shuffle=True, random_state=random_state\n",
    "        )\n",
    "        grid = GridSearchCV(\n",
    "            estimator=pipe,\n",
    "            param_grid=param_grid,\n",
    "            scoring=\"roc_auc\",\n",
    "            cv=inner_cv,\n",
    "            n_jobs=-1,\n",
    "            verbose=0,\n",
    "        )\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "            grid.fit(X_train, y_train)\n",
    "\n",
    "        best_model  = grid.best_estimator_\n",
    "        best_params = grid.best_params_\n",
    "\n",
    "        y_pred  = best_model.predict(X_test)\n",
    "        y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        metrics_records.append({\n",
    "            \"fold\": fold,\n",
    "            \"n_test\": len(test_idx),\n",
    "            \"auroc\": roc_auc_score(y_test, y_proba),\n",
    "            \"auprc\": average_precision_score(y_test, y_proba),\n",
    "            \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "            \"prevalence\": y_test.mean(),\n",
    "        })\n",
    "        param_records.append({\"fold\": fold, \"C\": best_params[\"clf__C\"]})\n",
    "\n",
    "        coef = best_model.named_steps[\"clf\"].coef_.flatten()\n",
    "        coef_records.append(pd.DataFrame({\n",
    "            \"feature\": X.columns,\n",
    "            \"coef\": coef,\n",
    "            \"abs_coef\": np.abs(coef),\n",
    "            \"fold\": fold,\n",
    "        }))\n",
    "\n",
    "        oof_records.append(pd.DataFrame({\n",
    "            id_col: ids.iloc[test_idx].values,\n",
    "            \"fold\":   fold,\n",
    "            \"y_true\": y_test.values,\n",
    "            \"y_proba\": y_proba,\n",
    "            \"y_pred\":  y_pred,\n",
    "        }))\n",
    "\n",
    "        fpr, tpr, _           = roc_curve(y_test, y_proba)\n",
    "        rec, prec, _          = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "        tpr_interp  = np.interp(fpr_grid, fpr, tpr)        # ↑ same grid for all folds\n",
    "        prec_interp = np.interp(recall_grid, rec[::-1], prec[::-1])\n",
    "\n",
    "        tpr_rows.append(tpr_interp)\n",
    "        prec_rows.append(prec_interp)\n",
    "\n",
    "        joblib.dump(\n",
    "            best_model,\n",
    "            os.path.join(output_dir, f\"enet_nested_best_fold{fold}.joblib\"),\n",
    "        )\n",
    "\n",
    "    metrics_df     = pd.DataFrame(metrics_records)\n",
    "    best_params_df = pd.DataFrame(param_records)\n",
    "    coef_df_all    = pd.concat(coef_records, ignore_index=True)\n",
    "    oof_df_all     = pd.concat(oof_records, ignore_index=True)\n",
    "\n",
    "    tpr_mat   = np.vstack(tpr_rows)    # shape: (n_folds, 101)\n",
    "    prec_mat  = np.vstack(prec_rows)   # shape: (n_folds, 101)\n",
    "    np.savez(\n",
    "        os.path.join(output_dir, \"nested_cv_curves.npz\"),\n",
    "        fpr_grid=fpr_grid,\n",
    "        tpr_mat=tpr_mat,\n",
    "        recall_grid=recall_grid,\n",
    "        prec_mat=prec_mat,\n",
    "    )\n",
    "\n",
    "    metrics_df.to_csv(os.path.join(output_dir, \"nested_cv_metrics.csv\"), index=False)\n",
    "    best_params_df.to_csv(os.path.join(output_dir, \"nested_best_params.csv\"), index=False)\n",
    "    coef_df_all.to_csv(os.path.join(output_dir, \"nested_coefficients.csv\"), index=False)\n",
    "    oof_df_all.to_csv(os.path.join(output_dir, \"nested_oof_predictions.csv\"), index=False)\n",
    "\n",
    "    return (\n",
    "        metrics_df,\n",
    "        best_params_df,\n",
    "        coef_df_all,\n",
    "        oof_df_all,\n",
    "        {\n",
    "            \"fpr_grid\": fpr_grid,\n",
    "            \"tpr_mat\":  tpr_mat,\n",
    "            \"recall_grid\": recall_grid,\n",
    "            \"prec_mat\": prec_mat,\n",
    "        },\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4a2c93-0069-4ff6-bffd-dbc54b8734ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train RABIT-trained model\n",
    "metrics_df, best_params_df, coef_df_all, oof_df_all, curve_info = nested_enet_cv(\n",
    "    rabit_proteomics,\n",
    "    id_col=\"sample_id\",\n",
    "    label_col=\"responder\",\n",
    "    output_dir=\"/path/to/rabit-trained/model\"\n",
    ")\n",
    "\n",
    "metrics_df[\"adjusted_auprc\"] = metrics_df[\"auprc\"] / metrics_df[\"prevalence\"]\n",
    "\n",
    "mean_row = {\n",
    "    \"fold\":            \"mean\",\n",
    "    \"auroc\":           metrics_df[\"auroc\"].mean(),\n",
    "    \"auprc\":           metrics_df[\"auprc\"].mean(),\n",
    "    \"accuracy\":        metrics_df[\"accuracy\"].mean(),\n",
    "    \"prevalence\":      metrics_df[\"prevalence\"].mean(),\n",
    "    \"adjusted_auprc\":  metrics_df[\"adjusted_auprc\"].mean(),\n",
    "}\n",
    "\n",
    "metrics_df = pd.concat([metrics_df, pd.DataFrame([mean_row])], ignore_index=True)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8423669e-49e0-4bef-9bf9-106feb5f6881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train External-trained model\n",
    "metrics_df, best_params_df, coef_df_all, oof_df_all, curve_info = nested_enet_cv(\n",
    "    external_cohort_proteomics,\n",
    "    id_col=\"sample_id\",\n",
    "    label_col=\"responder\",\n",
    "    output_dir=\"/path/to/external-trained/model\"\n",
    ")\n",
    "\n",
    "metrics_df[\"adjusted_auprc\"] = metrics_df[\"auprc\"] / metrics_df[\"prevalence\"]\n",
    "\n",
    "mean_row = {\n",
    "    \"fold\":            \"mean\",\n",
    "    \"auroc\":           metrics_df[\"auroc\"].mean(),\n",
    "    \"auprc\":           metrics_df[\"auprc\"].mean(),\n",
    "    \"accuracy\":        metrics_df[\"accuracy\"].mean(),\n",
    "    \"prevalence\":      metrics_df[\"prevalence\"].mean(),\n",
    "    \"adjusted_auprc\":  metrics_df[\"adjusted_auprc\"].mean(),\n",
    "}\n",
    "\n",
    "metrics_df = pd.concat([metrics_df, pd.DataFrame([mean_row])], ignore_index=True)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f86595-fd31-4cd8-87df-f02bfe89b668",
   "metadata": {},
   "source": [
    "# Run inference: external measured proteomics as input into RABIT-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5931db6-e552-47a8-9a60-94a3fb5b2d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths\n",
    "model_dir   = \"/path/to/RABIT-trained/model\"\n",
    "model_paths = sorted(glob.glob(f\"{model_dir}/enet_nested_best_fold*.joblib\"))\n",
    "id_col      = \"sample_id\"\n",
    "label_col   = \"responder\"          # must be 0/1\n",
    "\n",
    "df_new = external_df_cleaned_final\n",
    "assert label_col in df_new.columns, \"New data must contain ground-truth labels\"\n",
    "\n",
    "fpr_grid    = np.linspace(0.0, 1.0, 101)\n",
    "recall_grid = np.linspace(0.0, 1.0, 101)\n",
    "tpr_rows, prec_rows = [], []        \n",
    "\n",
    "# predict with every saved model\n",
    "proba_matrix   = []\n",
    "per_model_long = []\n",
    "\n",
    "for path in model_paths:\n",
    "    model = joblib.load(path)\n",
    "    features = model.feature_names_in_\n",
    "    X_raw    = df_new[features]\n",
    "\n",
    "    if isinstance(model, Pipeline):     # pipeline has imputer/scaler\n",
    "        proba = model.predict_proba(X_raw)[:, 1]\n",
    "    else:                             \n",
    "        scaler = StandardScaler()\n",
    "        proba = model.predict_proba(scaler.fit_transform(X_raw))[:, 1]\n",
    "\n",
    "    proba_matrix.append(proba)\n",
    "\n",
    "    fpr,  tpr,  _ = roc_curve(df_new[label_col], proba)\n",
    "    rec,  prec, _ = precision_recall_curve(df_new[label_col], proba)\n",
    "\n",
    "    # interpolate onto common grids\n",
    "    tpr_rows.append(np.interp(fpr_grid, fpr, tpr))\n",
    "    prec_rows.append(np.interp(recall_grid, rec[::-1], prec[::-1]))\n",
    "\n",
    "    # long-format rows for CSV\n",
    "    per_model_long.append(pd.DataFrame({\n",
    "        id_col:    df_new[id_col],\n",
    "        \"y_true\":  df_new[label_col],\n",
    "        \"y_proba\": proba,\n",
    "        \"model_id\": os.path.basename(path),\n",
    "    }))\n",
    "\n",
    "proba_matrix = np.vstack(proba_matrix)    \n",
    "proba_avg    = proba_matrix.mean(axis=0)\n",
    "pred_avg     = (proba_avg >= 0.5).astype(int)\n",
    "\n",
    "# aggregate metrics\n",
    "y_true     = df_new[label_col]\n",
    "auroc      = roc_auc_score(y_true, proba_avg)\n",
    "auprc      = average_precision_score(y_true, proba_avg)\n",
    "accuracy   = accuracy_score(y_true, pred_avg)\n",
    "prevalence = y_true.mean()\n",
    "adj_auprc  = auprc / prevalence if prevalence > 0 else np.nan\n",
    "\n",
    "metrics_df = pd.DataFrame([{\n",
    "    \"auroc\":          auroc,\n",
    "    \"auprc\":          auprc,\n",
    "    \"prevalence\":     prevalence,\n",
    "    \"adjusted_auprc\": adj_auprc,\n",
    "    \"accuracy\":       accuracy,\n",
    "    \"n_models\":       len(model_paths),\n",
    "    \"n_samples\":      len(df_new),\n",
    "}])\n",
    "\n",
    "print(metrics_df)\n",
    "\n",
    "tpr_mat  = np.vstack(tpr_rows)    \n",
    "prec_mat = np.vstack(prec_rows)\n",
    "\n",
    "np.savez(\n",
    "    f\"{model_dir}/per_model_curves.npz\",\n",
    "    fpr_grid=fpr_grid,\n",
    "    tpr_mat=tpr_mat,\n",
    "    recall_grid=recall_grid,\n",
    "    prec_mat=prec_mat,\n",
    ")\n",
    "\n",
    "fpr_ens,  tpr_ens,  _ = roc_curve(y_true, proba_avg)\n",
    "rec_ens,  prec_ens, _ = precision_recall_curve(y_true, proba_avg)\n",
    "np.savez(\n",
    "    f\"{model_dir}/ensemble_curve.npz\",\n",
    "    fpr=fpr_ens, tpr=tpr_ens, recall=rec_ens, precision=prec_ens\n",
    ")\n",
    "\n",
    "pred_path_ensemble = f\"{model_dir}/ensemble_predictions.csv\"\n",
    "pred_path_permdl   = f\"{model_dir}/per_model_predictions.csv\"\n",
    "metrics_path       = f\"{model_dir}/ensemble_metrics.csv\"\n",
    "\n",
    "pd.DataFrame({\n",
    "    id_col:    df_new[id_col],\n",
    "    \"y_true\":  y_true,\n",
    "    \"y_proba\": proba_avg,\n",
    "}).to_csv(pred_path_ensemble, index=False)\n",
    "\n",
    "pd.concat(per_model_long, ignore_index=True).to_csv(pred_path_permdl, index=False)\n",
    "metrics_df.to_csv(metrics_path, index=False)\n",
    "\n",
    "print(f\"Saved curves           → {model_dir}/per_model_curves.npz\")\n",
    "print(f\"Saved ensemble curve   → {model_dir}/ensemble_curve.npz\")\n",
    "print(f\"Saved ensemble preds   → {pred_path_ensemble}\")\n",
    "print(f\"Saved per-model preds  → {pred_path_permdl}\")\n",
    "print(f\"Saved metrics          → {metrics_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78db3b39-059c-4da9-bce7-eaeb6eed3112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89063f79-e45a-4986-b25b-631e17f33139",
   "metadata": {},
   "source": [
    "# Train clinical (age+sex) model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81a0ba0-3951-456f-80d7-f0084250df35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_enet_cv(\n",
    "    df: pd.DataFrame,\n",
    "    id_col: str,\n",
    "    label_col: str,\n",
    "    output_dir: str,\n",
    "    outer_splits: int = 5,\n",
    "    inner_splits: int = 10,\n",
    "    random_state: int = 42,\n",
    "    l1_ratio: float = 0.9,\n",
    "):\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    if not {\"age\", \"sex\"}.issubset(df.columns):\n",
    "        raise KeyError(\"Input df must contain 'age' and 'sex'.\")\n",
    "    X = (\n",
    "        df[[\"age\", \"sex\"]].copy()\n",
    "          .assign(sex=lambda d: d[\"sex\"]\n",
    "                              .str.lower()\n",
    "                              .map({\"female\": 0, \"male\": 1}))\n",
    "    )\n",
    "    y   = df[label_col]\n",
    "    ids = df[id_col]\n",
    "\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            penalty=\"elasticnet\", solver=\"saga\",\n",
    "            l1_ratio=l1_ratio, max_iter=20_000,\n",
    "            random_state=random_state, n_jobs=-1,\n",
    "        ))\n",
    "    ])\n",
    "    param_grid = {\"clf__C\": 10 ** np.linspace(-4, 4, 15)}\n",
    "\n",
    "    outer_cv = StratifiedKFold(\n",
    "        n_splits=outer_splits, shuffle=True, random_state=random_state\n",
    "    )\n",
    "\n",
    "    metrics_records, param_records, coef_records, oof_records = [], [], [], []\n",
    "\n",
    "    fpr_grid    = np.linspace(0.0, 1.0, 101)\n",
    "    recall_grid = np.linspace(0.0, 1.0, 101)\n",
    "    tpr_rows, prec_rows = [], []        # one row per outer fold\n",
    "\n",
    "    # outer fold cross validation\n",
    "    for fold, (train_idx, test_idx) in enumerate(\n",
    "        tqdm(list(outer_cv.split(X, y)), desc=\"Outer CV folds\"), start=1\n",
    "    ):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        inner_cv = StratifiedKFold(\n",
    "            n_splits=inner_splits, shuffle=True, random_state=random_state\n",
    "        )\n",
    "        grid = GridSearchCV(\n",
    "            estimator=pipe, param_grid=param_grid,\n",
    "            scoring=\"roc_auc\", cv=inner_cv,\n",
    "            n_jobs=-1, verbose=0,\n",
    "        )\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "            grid.fit(X_train, y_train)\n",
    "\n",
    "        best_model  = grid.best_estimator_\n",
    "        best_params = grid.best_params_\n",
    "\n",
    "        y_pred  = best_model.predict(X_test)\n",
    "        y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        metrics_records.append({\n",
    "            \"fold\":       fold,\n",
    "            \"n_test\":     len(test_idx),        # DD. store size\n",
    "            \"auroc\":      roc_auc_score(y_test, y_proba),\n",
    "            \"auprc\":      average_precision_score(y_test, y_proba),\n",
    "            \"accuracy\":   accuracy_score(y_test, y_pred),\n",
    "            \"prevalence\": y_test.mean(),\n",
    "        })\n",
    "        param_records.append({\"fold\": fold, \"C\": best_params[\"clf__C\"]})\n",
    "\n",
    "        coef = best_model.named_steps[\"clf\"].coef_.flatten()\n",
    "        coef_records.append(pd.DataFrame({\n",
    "            \"feature\":  X.columns,\n",
    "            \"coef\":     coef,\n",
    "            \"abs_coef\": np.abs(coef),\n",
    "            \"fold\":     fold,\n",
    "        }))\n",
    "\n",
    "        oof_records.append(pd.DataFrame({\n",
    "            id_col:   ids.iloc[test_idx].values,\n",
    "            \"fold\":   fold,\n",
    "            \"y_true\": y_test.values,\n",
    "            \"y_proba\": y_proba,\n",
    "            \"y_pred\":  y_pred,\n",
    "        }))\n",
    "\n",
    "        fpr, tpr, _        = roc_curve(y_test, y_proba)\n",
    "        rec, prec, _       = precision_recall_curve(y_test, y_proba)\n",
    "        tpr_rows.append(np.interp(fpr_grid, fpr, tpr))\n",
    "        prec_rows.append(np.interp(recall_grid, rec[::-1], prec[::-1]))\n",
    "\n",
    "        # Save model\n",
    "        joblib.dump(\n",
    "            best_model,\n",
    "            os.path.join(output_dir, f\"enet_nested_best_fold{fold}.joblib\"),\n",
    "        )\n",
    "\n",
    "    metrics_df     = pd.DataFrame(metrics_records)\n",
    "    best_params_df = pd.DataFrame(param_records)\n",
    "    coef_df_all    = pd.concat(coef_records, ignore_index=True)\n",
    "    oof_df_all     = pd.concat(oof_records, ignore_index=True)\n",
    "\n",
    "    tpr_mat  = np.vstack(tpr_rows)      # (outer_splits × 101)\n",
    "    prec_mat = np.vstack(prec_rows)\n",
    "    np.savez(\n",
    "        os.path.join(output_dir, \"nested_cv_curves.npz\"),\n",
    "        fpr_grid=fpr_grid,\n",
    "        tpr_mat=tpr_mat,\n",
    "        recall_grid=recall_grid,\n",
    "        prec_mat=prec_mat,\n",
    "    )\n",
    "\n",
    "    metrics_df.to_csv(os.path.join(output_dir, \"nested_cv_metrics.csv\"), index=False)\n",
    "    best_params_df.to_csv(os.path.join(output_dir, \"nested_best_params.csv\"), index=False)\n",
    "    coef_df_all.to_csv(os.path.join(output_dir, \"nested_coefficients.csv\"), index=False)\n",
    "    oof_df_all.to_csv(os.path.join(output_dir, \"nested_oof_predictions.csv\"), index=False)\n",
    "\n",
    "    curves = dict(fpr_grid=fpr_grid, tpr_mat=tpr_mat,\n",
    "                  recall_grid=recall_grid, prec_mat=prec_mat)\n",
    "\n",
    "    return metrics_df, best_params_df, coef_df_all, oof_df_all, curves\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "metrics_df, best_params_df, coef_df_all, oof_df_all, curves_nested = nested_enet_cv(\n",
    "    clinical_model_input,\n",
    "    id_col=\"sample_id\",\n",
    "    label_col=\"responder\",\n",
    "    output_dir=\"/path/to/clinical/model\"\n",
    ")\n",
    "\n",
    "\n",
    "metrics_df[\"adjusted_auprc\"] = metrics_df[\"auprc\"] / metrics_df[\"prevalence\"]\n",
    "\n",
    "mean_row = {\n",
    "    \"fold\":            \"mean\",\n",
    "    \"auroc\":           metrics_df[\"auroc\"].mean(),\n",
    "    \"auprc\":           metrics_df[\"auprc\"].mean(),\n",
    "    \"accuracy\":        metrics_df[\"accuracy\"].mean(),\n",
    "    \"prevalence\":      metrics_df[\"prevalence\"].mean(),\n",
    "    \"adjusted_auprc\":  metrics_df[\"adjusted_auprc\"].mean(),\n",
    "}\n",
    "\n",
    "metrics_df = pd.concat([metrics_df, pd.DataFrame([mean_row])], ignore_index=True)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f5e643-9425-4244-b428-c70d86a25a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "model_dir   = \"/path/to/clinical/model\"\n",
    "model_paths = sorted(glob.glob(f\"{model_dir}/enet_nested_best_fold*.joblib\"))\n",
    "id_col      = \"sample_id\"\n",
    "label_col   = \"responder\"        \n",
    "df_new = external_df_cleaned_clinical\n",
    "assert label_col in df_new.columns, \"New data must contain ground-truth labels\"\n",
    "\n",
    "fpr_grid    = np.linspace(0.0, 1.0, 101)\n",
    "recall_grid = np.linspace(0.0, 1.0, 101)\n",
    "tpr_rows, prec_rows = [], []         \n",
    "\n",
    "proba_matrix   = []\n",
    "per_model_long = []\n",
    "\n",
    "for path in model_paths:\n",
    "    model    = joblib.load(path)          \n",
    "    features = model.feature_names_in_   \n",
    "    X_new    = df_new[features]\n",
    "\n",
    "    proba = model.predict_proba(X_new)[:, 1]     \n",
    "    proba_matrix.append(proba)\n",
    "\n",
    "    fpr,  tpr,  _ = roc_curve(df_new[label_col], proba)\n",
    "    rec,  prec, _ = precision_recall_curve(df_new[label_col], proba)\n",
    "\n",
    "    tpr_rows.append(np.interp(fpr_grid, fpr, tpr))\n",
    "    prec_rows.append(np.interp(recall_grid, rec[::-1], prec[::-1]))\n",
    "\n",
    "    # long-format rows\n",
    "    per_model_long.append(pd.DataFrame({\n",
    "        id_col:   df_new[id_col],\n",
    "        \"y_true\": df_new[label_col],\n",
    "        \"y_proba\": proba,\n",
    "        \"model_id\": os.path.basename(path),\n",
    "    }))\n",
    "\n",
    "proba_matrix = np.vstack(proba_matrix)         \n",
    "proba_avg    = proba_matrix.mean(axis=0)\n",
    "pred_avg     = (proba_avg >= 0.5).astype(int)\n",
    "\n",
    "y_true     = df_new[label_col]\n",
    "auroc      = roc_auc_score(y_true, proba_avg)\n",
    "auprc      = average_precision_score(y_true, proba_avg)\n",
    "accuracy   = accuracy_score(y_true, pred_avg)\n",
    "prevalence = y_true.mean()\n",
    "adj_auprc  = auprc / prevalence if prevalence > 0 else np.nan\n",
    "\n",
    "metrics_df = pd.DataFrame([{\n",
    "    \"auroc\":          auroc,\n",
    "    \"auprc\":          auprc,\n",
    "    \"prevalence\":     prevalence,\n",
    "    \"adjusted_auprc\": adj_auprc,\n",
    "    \"accuracy\":       accuracy,\n",
    "    \"n_models\":       len(model_paths),\n",
    "    \"n_samples\":      len(df_new),\n",
    "}])\n",
    "\n",
    "print(metrics_df)\n",
    "\n",
    "tpr_mat  = np.vstack(tpr_rows)      # shape: (n_models × 101)\n",
    "prec_mat = np.vstack(prec_rows)\n",
    "\n",
    "np.savez(\n",
    "    f\"{model_dir}/per_model_curves_external_clinical.npz\",\n",
    "    fpr_grid=fpr_grid, tpr_mat=tpr_mat,\n",
    "    recall_grid=recall_grid, prec_mat=prec_mat,\n",
    ")\n",
    "\n",
    "fpr_ens,  tpr_ens,  _ = roc_curve(y_true, proba_avg)\n",
    "rec_ens,  prec_ens, _ = precision_recall_curve(y_true, proba_avg)\n",
    "np.savez(\n",
    "    f\"{model_dir}/ensemble_curve_external_clinical.npz\",\n",
    "    fpr=fpr_ens, tpr=tpr_ens, recall=rec_ens, precision=prec_ens\n",
    ")\n",
    "\n",
    "pred_path_ensemble = f\"{model_dir}/ensemble_predictions.csv\"\n",
    "pred_path_permdl   = f\"{model_dir}/per_model_predictions.csv\"\n",
    "metrics_path       = f\"{model_dir}/ensemble_metrics.csv\"\n",
    "\n",
    "pd.DataFrame({\n",
    "    id_col:   df_new[id_col],\n",
    "    \"y_true\": y_true,\n",
    "    \"y_proba\": proba_avg,\n",
    "}).to_csv(pred_path_ensemble, index=False)\n",
    "\n",
    "pd.concat(per_model_long, ignore_index=True).to_csv(pred_path_permdl, index=False)\n",
    "metrics_df.to_csv(metrics_path, index=False)\n",
    "\n",
    "print(f\"Saved per-model curves   → {model_dir}/per_model_curves.npz\")\n",
    "print(f\"Saved ensemble curve     → {model_dir}/ensemble_curve.npz\")\n",
    "print(f\"Saved ensemble preds     → {pred_path_ensemble}\")\n",
    "print(f\"Saved per-model preds    → {pred_path_permdl}\")\n",
    "print(f\"Saved metrics            → {metrics_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1253cad9-f380-41d6-8e80-de17678b9f07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37713872-a2da-45a7-9cfe-541cf55ea489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for visualization\n",
    "def _load(csv_or_buf):\n",
    "    df = pd.read_csv(csv_or_buf)\n",
    "    return df[\"y_true\"].values, df[\"y_proba\"].values\n",
    "\n",
    "\n",
    "def plot_curves(\n",
    "    csv_files,\n",
    "    *,\n",
    "    kind: str = \"roc\",\n",
    "    title: str | None = None,\n",
    "    ax=None,\n",
    "    grid_kwargs: dict | None = None,\n",
    "    legend_kwargs: dict | None = None,\n",
    "    save: bool = True,\n",
    "    out_dir: str | os.PathLike = (\n",
    "        \"/path/for/figures\"\n",
    "    ),\n",
    "    filename: str | None = None,\n",
    "):\n",
    "\n",
    "    grid_kwargs = grid_kwargs or {\n",
    "        \"which\": \"both\",\n",
    "        \"linestyle\": \"--\",\n",
    "        \"linewidth\": 0.5,\n",
    "        \"alpha\": 0.5,\n",
    "    }\n",
    "    legend_kwargs = legend_kwargs or {\"loc\": \"lower right\", \"frameon\": False}\n",
    "\n",
    "    created_fig = ax is None\n",
    "    if created_fig:\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    else:\n",
    "        fig = ax.figure  # grab parent figure\n",
    "\n",
    "    # ── curves ──────────────────────────────────────────────────────\n",
    "    for label, path in csv_files:\n",
    "        y_true, y_proba = _load(path)\n",
    "\n",
    "        if kind == \"roc\":\n",
    "            fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "            score = auc(fpr, tpr)\n",
    "            ax.plot(fpr, tpr, lw=1.6, label=f\"{label} (AUC {score:.3f})\")\n",
    "        else:\n",
    "            prec, rec, _ = precision_recall_curve(y_true, y_proba)\n",
    "            score = average_precision_score(y_true, y_proba)\n",
    "            ax.plot(rec, prec, lw=1.6, label=f\"{label} (AUPRC {score:.3f})\")\n",
    "\n",
    "    # ── cosmetics ───────────────────────────────────────────────────\n",
    "    if kind == \"roc\":\n",
    "        ax.plot([0, 1], [0, 1], \"--\", color=\"grey\", lw=1)\n",
    "        ax.set(xlabel=\"False-positive rate\", ylabel=\"True-positive rate\")\n",
    "    else:\n",
    "        # baseline = prevalence\n",
    "        baseline = y_true.mean()\n",
    "        ax.hlines(baseline, 0, 1, ls=\"--\", color=\"grey\", lw=1)\n",
    "        ax.set(xlabel=\"Recall\", ylabel=\"Precision\")\n",
    "\n",
    "    ax.set_title(\n",
    "        title or (\"ROC curve\" if kind == \"roc\" else \"Precision-Recall curve\")\n",
    "    )\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.grid(True, **grid_kwargs)\n",
    "    ax.legend(**legend_kwargs)\n",
    "\n",
    "    if save and created_fig:           \n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        def _slug(s: str) -> str:\n",
    "            return (\n",
    "                str(s)\n",
    "                .strip()\n",
    "                .replace(\" \", \"_\")\n",
    "                .replace(\"/\", \"_\")\n",
    "                .replace(\"\\\\\", \"_\")\n",
    "            )\n",
    "\n",
    "        if filename is None:\n",
    "            base = title or kind.upper()\n",
    "            filename = f\"{_slug(base)}_{kind}.pdf\"\n",
    "\n",
    "        pdf_path = os.path.join(out_dir, filename)\n",
    "        fig.savefig(pdf_path, format=\"pdf\", bbox_inches=\"tight\")\n",
    "        print(f\"✅  Figure saved → {pdf_path}\")\n",
    "\n",
    "    if created_fig:\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "        return fig, ax\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ── customise these paths ───────────────────────────────────────────────\n",
    "csv_protein = \"/path/to/RABIT-trained/model/nested_oof_predictions.csv\"\n",
    "csv_clinic  = \"/path/to/clinical/model/nested_oof_predictions.csv\"\n",
    "\n",
    "pairs = [(\"RABIT-trained Model\", csv_protein),\n",
    "         (\"Age + Sex Model\", csv_clinic)]\n",
    "\n",
    "# ── draw the plots ──────────────────────────────────────────────────────\n",
    "plot_curves(pairs, kind=\"roc\", title=\"AUROC comparison on RABIT cohort\")\n",
    "\n",
    "plot_curves(pairs, kind=\"pr\",  title=\"AUPRC comparison on RABIT cohort\", save=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a745eca-0e87-4339-9f6f-73b3e187cba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── customise these paths ───────────────────────────────────────────────\n",
    "csv_rabit = \"/path/to/RABIT-trained/model/ensemble_predictions.csv\"\n",
    "csv_clinic  = \"/path/to/clinical/model/ensemble_predictions.csv\"\n",
    "csv_external  = \"/path/to/external-trained/model/nested_oof_predictions.csv\"\n",
    "\n",
    "pairs = [(\"RABIT-trained Model\", csv_rabit),\n",
    "         (\"Age + Sex Model\", csv_clinic),\n",
    "         (\"External-trained Model\", csv_external)]\n",
    "\n",
    "# ── draw the plots ──────────────────────────────────────────────────────\n",
    "plot_curves(pairs, kind=\"roc\", title=\"AUROC comparison on External cohort\")\n",
    "plot_curves(pairs, kind=\"pr\",  title=\"AUPRC comparison on External cohort\", save=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b83257-91d8-4483-a025-eeedcbab91f3",
   "metadata": {},
   "source": [
    "# Logistic Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fff84ce-85d8-4ca9-a8c2-48675c7334e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert coefficients into odds ratios\n",
    "coef_df = pd.read_csv(\"/path/to/RABIT-trained/model/nested_coefficients.csv\")\n",
    "\n",
    "avg_coef_df = (\n",
    "    coef_df\n",
    "    .groupby(\"feature\", as_index=False)[\"coef\"]\n",
    "    .mean()\n",
    "    .rename(columns={\"coef\": \"avg_coef\"})\n",
    ")\n",
    "\n",
    "avg_coef_df[\"abs_coef\"]   = avg_coef_df[\"avg_coef\"].abs()\n",
    "avg_coef_df[\"odds_ratio\"] = np.exp(avg_coef_df[\"avg_coef\"])\n",
    "\n",
    "coef_df_sorted = (\n",
    "    avg_coef_df\n",
    "    .sort_values(by=\"odds_ratio\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "coef_df_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055c2e43-5073-4249-9cd0-7309b39029d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for visualization\n",
    "def plot_odds_ratios(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    top_n: int = 10,         \n",
    "    print_n: int = 10,       \n",
    "    save: bool = True,\n",
    "    out_dir: str | os.PathLike = (\n",
    "        \"/path/to/figures\"\n",
    "    ),\n",
    "    filename: str | None = None,\n",
    "):\n",
    "\n",
    "    required = {\"feature\", \"odds_ratio\"}\n",
    "    if not required.issubset(df.columns):\n",
    "        raise KeyError(f\"DataFrame must include columns {required}\")\n",
    "\n",
    "    df_sorted = df.sort_values(\"odds_ratio\")\n",
    "    if 0 < top_n * 2 <= len(df_sorted):\n",
    "        df_plot = pd.concat([df_sorted.head(top_n), df_sorted.tail(top_n)])\n",
    "    else:\n",
    "        df_plot = df_sorted\n",
    "    df_plot = df_plot.sort_values(\"odds_ratio\").reset_index(drop=True)\n",
    "\n",
    "    # ── plotting ─────────────────────────────────────────────────────\n",
    "    fig, ax = plt.subplots(figsize=(0.55 * len(df_plot) + 2, 6))\n",
    "    x = np.arange(len(df_plot))\n",
    "    colors = [\"red\" if or_ < 1 else \"steelblue\" for or_ in df_plot[\"odds_ratio\"]]\n",
    "    heights = df_plot[\"odds_ratio\"] - 1\n",
    "\n",
    "    ax.bar(\n",
    "        x,\n",
    "        heights,\n",
    "        bottom=1,\n",
    "        color=colors,\n",
    "        edgecolor=\"black\",\n",
    "        width=0.8,\n",
    "    )\n",
    "\n",
    "    ax.axhline(1, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(df_plot[\"feature\"], rotation=90, ha=\"center\", fontsize=8)\n",
    "    ax.set_xlabel(\"Proteins (ordered by odds ratio)\")\n",
    "\n",
    "    ymin = min(0.8, df_plot[\"odds_ratio\"].min() * 0.95)\n",
    "    ymax = max(1.2, df_plot[\"odds_ratio\"].max() * 1.05)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.set_ylabel(\"Odds ratio\")\n",
    "    ax.set_title(f\"{len(df_plot)} extreme proteins (±{top_n}) by odds ratio\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        if filename is None:\n",
    "            filename = f\"odds_ratio_extremes_top{top_n}.pdf\"\n",
    "        pdf_path = os.path.join(out_dir, filename)\n",
    "        fig.savefig(pdf_path, format=\"pdf\", bbox_inches=\"tight\")\n",
    "        print(f\"✅  Figure saved → {pdf_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # ── print extremes ───────────────────────────────────────────────\n",
    "    smallest_print = df_sorted.head(print_n)\n",
    "    largest_print = df_sorted.tail(print_n)\n",
    "\n",
    "    print(f\"\\n{print_n} smallest odds ratios:\")\n",
    "    print(\", \".join(smallest_print[\"feature\"].tolist()))\n",
    "\n",
    "    print(f\"\\n{print_n} largest odds ratios:\")\n",
    "    print(\", \".join(largest_print[\"feature\"].tolist()))\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "plot_odds_ratios(coef_df_sorted, top_n=10, print_n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade82a08-e101-458b-8af4-b4be38c7d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert coefficients into odds ratios\n",
    "coef_df_external = pd.read_csv(\"/path/to/external-trained/model/nested_coefficients.csv\")\n",
    "\n",
    "avg_coef_df_external = (\n",
    "    coef_df_external\n",
    "    .groupby(\"feature\", as_index=False)[\"coef\"]\n",
    "    .mean()\n",
    "    .rename(columns={\"coef\": \"avg_coef\"})\n",
    ")\n",
    "\n",
    "avg_coef_df_external[\"abs_coef\"]   = avg_coef_df_external[\"avg_coef\"].abs()\n",
    "avg_coef_df_external[\"odds_ratio\"] = np.exp(avg_coef_df_external[\"avg_coef\"])\n",
    "\n",
    "coef_df_sorted_external = (\n",
    "    avg_coef_df_external\n",
    "    .sort_values(by=\"odds_ratio\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "coef_df_sorted_external.to_csv('./external_prot_features.csv', index=False)\n",
    "plot_odds_ratios(coef_df_sorted_external, top_n=10, print_n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9704e0b4-9aba-453a-bacf-90cd9738a3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmi_df = pd.read_csv('./ehr_measurements_tables/bmi_3038553.csv')\n",
    "bmi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4608a6ba-296b-49f0-9db4-9c5d1ca124eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "antitnf_patients = pd.read_csv('./labels/rabit_antitnf_labels.csv')\n",
    "antitnf_patients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7ebfba-027d-46ef-98c1-fbf36b3b1d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7270bd5-6ca5-4e34-ab22-8636d720c9a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_patient_measurement_dict(labeldf: pd.DataFrame,\n",
    "                                   measdf: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    For each patient in `labeldf`, grab their prediction_time and all measurements\n",
    "    from `measdf`, sorted by measurement_DATE, collecting each column as a list.\n",
    "    At the end, prints:\n",
    "      - count of patients with ≥1 measurement\n",
    "      - count of patients with ≥5 measurements\n",
    "      - summary statistics of how many measurements each patient has.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labeldf : pd.DataFrame\n",
    "        Must contain columns ['patient_id', 'prediction_time'].\n",
    "    measdf : pd.DataFrame\n",
    "        Must contain columns [\n",
    "            'person_id',\n",
    "            'measurement_concept_id',\n",
    "            'measurement_DATE',\n",
    "            'value_as_number',\n",
    "            'value_as_concept_id',\n",
    "            'measurement_source_value',\n",
    "            'measurement_source_concept_id',\n",
    "            'unit_source_value'\n",
    "        ].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Keys are patient_id (from labeldf). Values are dicts with:\n",
    "            - 'prediction_time': single value\n",
    "            - one entry per measurement column, where the value is a list\n",
    "              of all that patient’s entries (in date order).\n",
    "    \"\"\"\n",
    "    # Subset the columns we care about\n",
    "    label_sub = labeldf[['patient_id', 'prediction_time']].drop_duplicates()\n",
    "    meas_sub = measdf[[\n",
    "        'person_id',\n",
    "        'measurement_concept_id',\n",
    "        'measurement_DATE',\n",
    "        'value_as_number',\n",
    "        'value_as_concept_id',\n",
    "        'measurement_source_value',\n",
    "        'measurement_source_concept_id',\n",
    "        'unit_source_value'\n",
    "    ]]\n",
    "\n",
    "    result = {}\n",
    "    # Build the nested dict\n",
    "    for _, lab_row in label_sub.iterrows():\n",
    "        pid = lab_row['patient_id']\n",
    "        pred_time = lab_row['prediction_time']\n",
    "\n",
    "        patient_meas = (\n",
    "            meas_sub[meas_sub['person_id'] == pid]\n",
    "            .sort_values(by='measurement_DATE')\n",
    "        )\n",
    "\n",
    "        entry = {'prediction_time': pred_time}\n",
    "        for col in [\n",
    "            'measurement_concept_id',\n",
    "            'measurement_DATE',\n",
    "            'value_as_number',\n",
    "            'value_as_concept_id',\n",
    "            'measurement_source_value',\n",
    "            'measurement_source_concept_id',\n",
    "            'unit_source_value'\n",
    "        ]:\n",
    "            entry[col] = patient_meas[col].tolist()\n",
    "\n",
    "        result[pid] = entry\n",
    "\n",
    "    # Compute per-patient counts\n",
    "    counts = pd.Series(\n",
    "        [len(d['measurement_concept_id']) for d in result.values()],\n",
    "        name='num_measurements'\n",
    "    )\n",
    "\n",
    "    # Print the requested statistics\n",
    "    num_at_least_1 = (counts >= 1).sum()\n",
    "    num_at_least_5 = (counts >= 5).sum()\n",
    "\n",
    "    print(f\"Patients with ≥1 measurement: {num_at_least_1}\")\n",
    "    print(f\"Patients with ≥5 measurements: {num_at_least_5}\")\n",
    "    print(\"\\nSummary of measurement counts per patient:\")\n",
    "    print(counts.describe())\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "patient_dict_all = build_patient_measurement_dict(antitnf_patients, bmi_df) # for bmi\n",
    "\n",
    "patient_dict_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4857af7c-b4f0-46b3-9195-ffa51075031c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Subset result for rheumatoid arthritis patients\n",
    "patient_dict = {k: patient_dict_all[k]          # keep the original value\n",
    "            for k in ra_patients_with_antitnf                  # iterate over the keys you care about\n",
    "            if k in patient_dict_all}      # guard against missing keys\n",
    "patient_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902a4810-5a56-4461-817c-0cdfbb7508f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(patient_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43624e1d-c28d-4cae-ae4c-0c4a7b00d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_patient_time_series(patient_dict):\n",
    "    \"\"\"\n",
    "    Draws a line for each patient showing value_as_number over time,\n",
    "    and prints how many patients were plotted.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    patient_dict : dict\n",
    "        Nested dict from build_patient_measurement_dict(), e.g.:\n",
    "        {\n",
    "          patient_id1: {\n",
    "            'measurement_DATE': [date1, date2, …],\n",
    "            'value_as_number': [val1, val2, …],\n",
    "            …\n",
    "          },\n",
    "          patient_id2: { … },\n",
    "          …\n",
    "        }\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plotted_count = 0\n",
    "\n",
    "    for pid, data in patient_dict.items():\n",
    "        dates = pd.to_datetime(data['measurement_DATE'])\n",
    "        values = data['value_as_number']\n",
    "        if len(dates) > 0:\n",
    "            plt.plot(dates, values, label=str(pid), alpha=0.6)\n",
    "            plotted_count += 1\n",
    "\n",
    "    # Print total number of patients plotted\n",
    "    print(f\"Total patients plotted: {plotted_count}\")\n",
    "\n",
    "    plt.xlabel(\"Measurement Date\")\n",
    "    plt.ylabel(\"Value as Number\")\n",
    "    plt.title(\"Patient Measurements Over Time\")\n",
    "    plt.gcf().autofmt_xdate()  # rotate date labels\n",
    "\n",
    "    # only show legend if few patients\n",
    "    if plotted_count <= 20:\n",
    "        plt.legend(title=\"Patient ID\", bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "    else:\n",
    "        # too many lines to label individually: annotate count on the plot\n",
    "        plt.annotate(f\"{plotted_count} patients\", \n",
    "                     xy=(0.99, 0.01),\n",
    "                     xycoords='axes fraction',\n",
    "                     ha='right', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_patient_time_series(patient_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f89afe6-5b3b-4f48-9b58-ff51b80f50f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_extreme_values(patient_dict, low=10, high=70):\n",
    "    \"\"\"\n",
    "    Count how many individual measurements and how many patients have\n",
    "    value_as_number < low or > high.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    patient_dict : dict\n",
    "        Nested dict as returned by build_patient_measurement_dict(), e.g.:\n",
    "        {\n",
    "          patient_id1: {\n",
    "            'value_as_number': [ … ],\n",
    "            …\n",
    "          },\n",
    "          …\n",
    "        }\n",
    "    low : float\n",
    "        Lower threshold.\n",
    "    high : float\n",
    "        Upper threshold.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple (int, int)\n",
    "        (total_extreme_entries, num_patients_with_extremes)\n",
    "    \"\"\"\n",
    "    total_extreme_entries = 0\n",
    "    num_patients_with_extremes = 0\n",
    "\n",
    "    for pid, data in patient_dict.items():\n",
    "        # get the list of values, drop any None/NaN\n",
    "        vals = pd.to_numeric(data.get('value_as_number', []), errors='coerce')\n",
    "        # boolean mask of extremes\n",
    "        mask = (vals < low) | (vals > high)\n",
    "        count = mask.sum()\n",
    "        if count > 0:\n",
    "            num_patients_with_extremes += 1\n",
    "            total_extreme_entries += int(count)\n",
    "\n",
    "    return total_extreme_entries, num_patients_with_extremes\n",
    "\n",
    "\n",
    "ext_entries, ext_patients = count_extreme_values(patient_dict, low=30, high=400)\n",
    "print(f\"Entries with value_as_number < 10 or > 70: {ext_entries}\")\n",
    "print(f\"Patients with ≥1 such entry: {ext_patients}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a3d781-6dd7-4c1c-a344-3b1608bea8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_patient_measurements(patient_dict, low=10, high=70):\n",
    "    \"\"\"\n",
    "    Remove all entries where value_as_number < low or value_as_number > high\n",
    "    from each patient’s record in the nested dict. All other lists are\n",
    "    filtered in parallel so entries stay aligned.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    patient_dict : dict\n",
    "        Nested dict as returned by build_patient_measurement_dict(), e.g.:\n",
    "        {\n",
    "          patient_id1: {\n",
    "            'prediction_time': ...,\n",
    "            'measurement_concept_id': [...],\n",
    "            'measurement_DATE': [...],\n",
    "            'value_as_number': [...],\n",
    "            ... \n",
    "          },\n",
    "          ...\n",
    "        }\n",
    "    low : float\n",
    "        Lower bound (inclusive).\n",
    "    high : float\n",
    "        Upper bound (inclusive).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A new dict with the same structure, but with out‐of‐range entries removed.\n",
    "    \"\"\"\n",
    "    filtered = {}\n",
    "    for pid, data in patient_dict.items():\n",
    "        vals = data.get('value_as_number', [])\n",
    "        # determine which indices to keep\n",
    "        keep_idxs = []\n",
    "        for i, v in enumerate(vals):\n",
    "            try:\n",
    "                if low <= v <= high:\n",
    "                    keep_idxs.append(i)\n",
    "            except Exception:\n",
    "                # skip non-numeric or missing values\n",
    "                continue\n",
    "\n",
    "        # rebuild each list in data by selecting only kept indices\n",
    "        new_data = {'prediction_time': data['prediction_time']}\n",
    "        for key, lst in data.items():\n",
    "            if key == 'prediction_time':\n",
    "                continue\n",
    "            new_data[key] = [lst[i] for i in keep_idxs]\n",
    "\n",
    "        filtered[pid] = new_data\n",
    "\n",
    "    return filtered\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4137f16d-500c-44d8-afb5-41806550b7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For BMI\n",
    "filtered_patient_dict = filter_patient_measurements(patient_dict, low=10, high=70)\n",
    "ext_entries, ext_patients = count_extreme_values(filtered_patient_dict, low=10, high=70)\n",
    "print(f\"Entries with value_as_number < 10 or > 70: {ext_entries}\")\n",
    "print(f\"Patients with ≥1 such entry: {ext_patients}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a000aa2-eff9-4d23-9f42-f8b2e705b64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_patient_time_series(filtered_patient_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eefb19e-871b-4c51-8381-349635d7c6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "def plot_time_series_by_response(patient_dict: dict,\n",
    "                                 responsedf: pd.DataFrame,\n",
    "                                 normalize: bool = False):\n",
    "    \"\"\"\n",
    "    Plot each patient’s value_as_number over time, coloring responders blue\n",
    "    and non-responders red, with a best-fit trend line per group.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    patient_dict : dict\n",
    "        Nested dict from build_patient_measurement_dict(), keyed by patient_id.\n",
    "    responsedf : pd.DataFrame\n",
    "        Must contain ['person_id', 'responder'] where responder is True/False.\n",
    "    normalize : bool, default False\n",
    "        If True, divide each patient’s values by their first value before plotting.\n",
    "    \"\"\"\n",
    "    # map patient → True/False\n",
    "    resp_map = dict(zip(responsedf['person_id'], responsedf['responder']))\n",
    "    responders    = [pid for pid in patient_dict if resp_map.get(pid) is True]\n",
    "    nonresponders = [pid for pid in patient_dict if resp_map.get(pid) is False]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # plot individual lines\n",
    "    for pid in responders:\n",
    "        dates = pd.to_datetime(patient_dict[pid]['measurement_DATE'])\n",
    "        raw_vals = np.array(patient_dict[pid]['value_as_number'], dtype=float)\n",
    "        vals = raw_vals / raw_vals[0] if normalize and raw_vals.size and raw_vals[0] else raw_vals\n",
    "        if vals.size:\n",
    "            plt.plot(dates, vals, color='blue', alpha=0.3)\n",
    "    for pid in nonresponders:\n",
    "        dates = pd.to_datetime(patient_dict[pid]['measurement_DATE'])\n",
    "        raw_vals = np.array(patient_dict[pid]['value_as_number'], dtype=float)\n",
    "        vals = raw_vals / raw_vals[0] if normalize and raw_vals.size and raw_vals[0] else raw_vals\n",
    "        if vals.size:\n",
    "            plt.plot(dates, vals, color='red', alpha=0.3)\n",
    "\n",
    "    # helper to fit & plot trend line\n",
    "    def _fit_and_plot(pids, color):\n",
    "        x_nums, y_vals = [], []\n",
    "        for pid in pids:\n",
    "            dates = pd.to_datetime(patient_dict[pid]['measurement_DATE'])\n",
    "            raw_vals = pd.to_numeric(patient_dict[pid]['value_as_number'], errors='coerce')\n",
    "            # raw_vals is already a NumPy array, so no .to_numpy()\n",
    "            if normalize and raw_vals.size and not np.isnan(raw_vals[0]) and raw_vals[0] != 0:\n",
    "                vals = raw_vals / raw_vals[0]\n",
    "            else:\n",
    "                vals = raw_vals\n",
    "            mask = ~np.isnan(vals)\n",
    "            if mask.any():\n",
    "                x_nums.append(mdates.date2num(dates[mask]))\n",
    "                y_vals.append(vals[mask])\n",
    "\n",
    "        if not x_nums:\n",
    "            return\n",
    "        x_all = np.concatenate(x_nums)\n",
    "        y_all = np.concatenate(y_vals)\n",
    "        slope, intercept = np.polyfit(x_all, y_all, 1)\n",
    "        x_fit = np.linspace(x_all.min(), x_all.max(), 100)\n",
    "        y_fit = slope * x_fit + intercept\n",
    "        dates_fit = mdates.num2date(x_fit)\n",
    "        plt.plot(dates_fit, y_fit, color=color, linewidth=2, label=f\"{color.title()} trend\")\n",
    "\n",
    "    # plot trend lines\n",
    "    _fit_and_plot(responders, 'blue')\n",
    "    _fit_and_plot(nonresponders, 'red')\n",
    "\n",
    "    # finalize\n",
    "    plt.xlabel(\"Measurement Date\")\n",
    "    ylabel = \"Normalized Value\" if normalize else \"Value as Number\"\n",
    "    plt.ylabel(ylabel)\n",
    "    title = \"Patient Measurements Over Time by Responder Status\"\n",
    "    if normalize:\n",
    "        title += \" (normalized)\"\n",
    "    plt.title(title)\n",
    "    plt.gcf().autofmt_xdate()\n",
    "\n",
    "    # dummy lines for the legend\n",
    "    plt.plot([], [], color='blue',  alpha=0.3, label=\"Responder\")\n",
    "    plt.plot([], [], color='red',   alpha=0.3, label=\"Non-responder\")\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_time_series_by_response(filtered_patient_dict, responder_df, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5548140-8559-4b43-8dcb-399113c709df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def plot_violin_by_response(patient_dict: dict,\n",
    "                            responsedf: pd.DataFrame,\n",
    "                            normalize: bool = False):\n",
    "    \"\"\"\n",
    "    Create a violin plot for the first and last measurements of each patient,\n",
    "    split by responder status, with paired dots and connecting lines.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    patient_dict : dict\n",
    "        Nested dict of patient measurements as from build_patient_measurement_dict().\n",
    "    responsedf : pd.DataFrame\n",
    "        DataFrame with columns ['person_id', 'responder'] (True/False).\n",
    "    normalize : bool, default False\n",
    "        If True, divide each patient’s values by their first measurement before plotting.\n",
    "    \"\"\"\n",
    "    # Build lookup of responder status\n",
    "    resp_map = dict(zip(responsedf['person_id'], responsedf['responder']))\n",
    "\n",
    "    # Containers for first/last values\n",
    "    resp_first, resp_last = [], []\n",
    "    nonr_first, nonr_last = [], []\n",
    "\n",
    "    for pid, data in patient_dict.items():\n",
    "        if pid not in resp_map:\n",
    "            continue\n",
    "        raw_vals = np.array(data['value_as_number'], dtype=float)\n",
    "        if raw_vals.size == 0:\n",
    "            continue\n",
    "        # normalize if requested\n",
    "        if normalize and raw_vals[0] and not np.isnan(raw_vals[0]):\n",
    "            vals = raw_vals / raw_vals[0]\n",
    "        else:\n",
    "            vals = raw_vals\n",
    "        first, last = vals[0], vals[-1]\n",
    "        if resp_map[pid]:\n",
    "            resp_first.append(first)\n",
    "            resp_last.append(last)\n",
    "        else:\n",
    "            nonr_first.append(first)\n",
    "            nonr_last.append(last)\n",
    "\n",
    "    # Prepare for plotting\n",
    "    groups = ['Resp First', 'Resp Last', 'NonR First', 'NonR Last']\n",
    "    data = [resp_first, resp_last, nonr_first, nonr_last]\n",
    "    positions = [0, 1, 3, 4]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    violins = ax.violinplot(data, positions=positions, widths=0.8, showmedians=True)\n",
    "\n",
    "    # Color violins\n",
    "    colors = ['lightblue', 'lightblue', 'salmon', 'salmon']\n",
    "    for body, col in zip(violins['bodies'], colors):\n",
    "        body.set_facecolor(col)\n",
    "        body.set_edgecolor('black')\n",
    "        body.set_alpha(0.5)\n",
    "\n",
    "    # Paired lines & dots for responders\n",
    "    for first, last in zip(resp_first, resp_last):\n",
    "        ax.plot([0, 1], [first, last], color='blue', alpha=0.3)\n",
    "    ax.scatter([0]*len(resp_first), resp_first, color='blue', edgecolor='black')\n",
    "    ax.scatter([1]*len(resp_last), resp_last, color='blue', edgecolor='black')\n",
    "\n",
    "    # Paired lines & dots for non-responders\n",
    "    for first, last in zip(nonr_first, nonr_last):\n",
    "        ax.plot([3, 4], [first, last], color='red', alpha=0.3)\n",
    "    ax.scatter([3]*len(nonr_first), nonr_first, color='red', edgecolor='black')\n",
    "    ax.scatter([4]*len(nonr_last), nonr_last, color='red', edgecolor='black')\n",
    "\n",
    "    # Labels & title\n",
    "    ax.set_xticks(positions)\n",
    "    ax.set_xticklabels(groups)\n",
    "    ylabel = 'Normalized Value' if normalize else 'Value as Number'\n",
    "    ax.set_ylabel(ylabel)\n",
    "    subtitle = \" (normalized)\" if normalize else \"\"\n",
    "    ax.set_title(f'First vs Last Measurement by Responder Status{subtitle}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_violin_by_response(filtered_patient_dict, responder_df, normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aaab81-8a15-4433-b595-119554787a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def plot_single_patient_time_series(patient_dict: dict,\n",
    "                                    responsedf: pd.DataFrame,\n",
    "                                    patient_id,\n",
    "                                    normalize: bool = False):\n",
    "    \"\"\"\n",
    "    Plot a single patient’s value_as_number over time.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    patient_dict : dict\n",
    "        Nested dict from build_patient_measurement_dict(), keyed by patient_id.\n",
    "    responsedf : pd.DataFrame\n",
    "        Must contain ['person_id', 'responder'] where responder is True/False.\n",
    "    patient_id : hashable\n",
    "        The identifier of the patient you want to plot.\n",
    "    normalize : bool, default False\n",
    "        If True, divide this patient’s values by their first measurement.\n",
    "    \"\"\"\n",
    "    # look up responder status\n",
    "    resp_map = dict(zip(responsedf['person_id'], responsedf['responder']))\n",
    "    is_resp = resp_map.get(patient_id, False)\n",
    "    color = 'blue' if is_resp else 'red'\n",
    "    label = f\"{patient_id} ({'responder' if is_resp else 'non-responder'})\"\n",
    "\n",
    "    # extract dates & values\n",
    "    dates = pd.to_datetime(patient_dict[patient_id]['measurement_DATE'])\n",
    "    raw_vals = np.array(patient_dict[patient_id]['value_as_number'], dtype=float)\n",
    "    if normalize and raw_vals.size and not np.isnan(raw_vals[0]) and raw_vals[0] != 0:\n",
    "        vals = raw_vals / raw_vals[0]\n",
    "    else:\n",
    "        vals = raw_vals\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(dates, vals, color=color, alpha=0.7, linewidth=2, label=label)\n",
    "\n",
    "    # labels & title\n",
    "    plt.xlabel(\"Measurement Date\")\n",
    "    ylabel = \"Normalized Value\" if normalize else \"Value as Number\"\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(f\"Patient {patient_id} Time Series\")\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# single patient, raw values\n",
    "plot_single_patient_time_series(patient_dict, responder_df, patient_id=30912777)\n",
    "\n",
    "# single patient, normalized to first measurement\n",
    "plot_single_patient_time_series(patient_dict, responder_df, patient_id=30912777, normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ecbc85-3811-45a4-9e32-63872a927123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "def plot_time_series_by_response_with_drug_window(\n",
    "        patient_dict: dict,\n",
    "        responsedf: pd.DataFrame,\n",
    "        drugdict: dict,\n",
    "        normalize: bool = False):\n",
    "    \"\"\"\n",
    "    Plot each patient’s value_as_number over time, but only between their\n",
    "    earliest and latest drug administration timestamps. If normalize=True,\n",
    "    divide each patient’s measurements by their first measurement that falls\n",
    "    within their drug-administration window.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    patient_dict : dict\n",
    "        Nested dict from build_patient_measurement_dict(), keyed by patient_id.\n",
    "    responsedf : pd.DataFrame\n",
    "        Must contain ['person_id', 'responder'] where responder is True/False.\n",
    "    drugdict : dict\n",
    "        {\n",
    "          patient_id1: {\n",
    "            'all_visits': [...],\n",
    "            'drug_administrations': [ts1, ts2, …]\n",
    "          },\n",
    "          ...\n",
    "        }\n",
    "    normalize : bool, default False\n",
    "        If True, normalize each patient’s values to the first value within\n",
    "        the drug-administration window.\n",
    "    \"\"\"\n",
    "    # Build responder lookup\n",
    "    resp_map = dict(zip(responsedf['person_id'], responsedf['responder']))\n",
    "    responders    = [pid for pid in patient_dict if resp_map.get(pid) is True]\n",
    "    nonresponders = [pid for pid in patient_dict if resp_map.get(pid) is False]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    def _get_drug_window(pid):\n",
    "        info = drugdict.get(pid, {})\n",
    "        times = info.get('drug_administrations', [])\n",
    "        ts = pd.to_datetime(pd.Series(times), errors='coerce').dropna()\n",
    "        if ts.empty:\n",
    "            return None, None\n",
    "        return ts.min(), ts.max()\n",
    "\n",
    "    # Plot each patient clipped to their drug window\n",
    "    for pid_list, color in [(responders, 'blue'), (nonresponders, 'red')]:\n",
    "        for pid in pid_list:\n",
    "            start, end = _get_drug_window(pid)\n",
    "            if start is None:\n",
    "                continue\n",
    "\n",
    "            # measurement dates & raw values\n",
    "            dates = pd.to_datetime(patient_dict[pid]['measurement_DATE'])\n",
    "            raw   = np.array(patient_dict[pid]['value_as_number'], dtype=float)\n",
    "\n",
    "            # mask to window and non-nans\n",
    "            mask_time = (dates >= start) & (dates <= end)\n",
    "            valid_mask = mask_time & (~np.isnan(raw))\n",
    "            if not valid_mask.any():\n",
    "                continue\n",
    "\n",
    "            # determine normalization factor\n",
    "            if normalize:\n",
    "                first_idx = np.where(valid_mask)[0][0]\n",
    "                norm_factor = raw[first_idx]\n",
    "                if norm_factor and not np.isnan(norm_factor):\n",
    "                    vals = raw / norm_factor\n",
    "                else:\n",
    "                    vals = raw.copy()\n",
    "            else:\n",
    "                vals = raw\n",
    "\n",
    "            # final mask for plotting\n",
    "            plot_mask = valid_mask\n",
    "            plt.plot(dates[plot_mask], vals[plot_mask], color=color, alpha=0.3)\n",
    "\n",
    "    # Helper to fit & plot group trend lines within drug windows\n",
    "    def _fit_and_plot(pids, color):\n",
    "        xnums, yvals = [], []\n",
    "        for pid in pids:\n",
    "            start, end = _get_drug_window(pid)\n",
    "            if start is None:\n",
    "                continue\n",
    "\n",
    "            dates = pd.to_datetime(patient_dict[pid]['measurement_DATE'])\n",
    "            raw   = pd.to_numeric(patient_dict[pid]['value_as_number'], errors='coerce')\n",
    "\n",
    "            mask_time = (dates >= start) & (dates <= end)\n",
    "            valid_mask = mask_time & (~pd.isna(raw))\n",
    "            if not valid_mask.any():\n",
    "                continue\n",
    "\n",
    "            if normalize:\n",
    "                first_idx = np.where(valid_mask)[0][0]\n",
    "                norm_factor = raw[first_idx]\n",
    "                if norm_factor and not np.isnan(norm_factor):\n",
    "                    vals = raw / norm_factor\n",
    "                else:\n",
    "                    vals = raw.copy()\n",
    "            else:\n",
    "                vals = raw\n",
    "\n",
    "            xnums.append(mdates.date2num(dates[valid_mask]))\n",
    "            yvals.append(vals[valid_mask])\n",
    "\n",
    "        if not xnums:\n",
    "            return\n",
    "        x_all = np.concatenate(xnums)\n",
    "        y_all = np.concatenate(yvals)\n",
    "        slope, intercept = np.polyfit(x_all, y_all, 1)\n",
    "        x_fit = np.linspace(x_all.min(), x_all.max(), 100)\n",
    "        y_fit = slope * x_fit + intercept\n",
    "        plt.plot(mdates.num2date(x_fit), y_fit, color=color, linewidth=2, label=f\"{color.title()} trend\")\n",
    "\n",
    "    _fit_and_plot(responders, 'blue')\n",
    "    _fit_and_plot(nonresponders, 'red')\n",
    "\n",
    "    # Final formatting\n",
    "    plt.xlabel(\"Measurement Date\")\n",
    "    ylabel = \"Normalized Value\" if normalize else \"Value as Number\"\n",
    "    plt.ylabel(ylabel)\n",
    "    title = \"Measurements Over Time by Responder Status\"\n",
    "    if normalize:\n",
    "        title += \" (normalized to first value in drug window)\"\n",
    "    plt.title(title)\n",
    "    plt.gcf().autofmt_xdate()\n",
    "\n",
    "    # Legend placeholders\n",
    "    plt.plot([], [], color='blue',  alpha=0.3, label=\"Responder\")\n",
    "    plt.plot([], [], color='red',   alpha=0.3, label=\"Non-responder\")\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_time_series_by_response_with_drug_window(\n",
    "    filtered_patient_dict,\n",
    "    responder_df,\n",
    "    summary_dict,\n",
    "    normalize=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183a2bf1-a83f-438c-b41e-d617e26d8f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "def plot_single_patient_with_drug_markers(patient_dict: dict,\n",
    "                                          responsedf: pd.DataFrame,\n",
    "                                          drugdict: dict,\n",
    "                                          patient_id,\n",
    "                                          normalize: bool = False):\n",
    "    \"\"\"\n",
    "    Plot a single patient’s measurements over their drug-administration window,\n",
    "    marking each drug administration with a green dot.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    patient_dict : dict\n",
    "        From build_patient_measurement_dict(); keyed by patient_id.\n",
    "    responsedf : pd.DataFrame\n",
    "        Must have ['person_id', 'responder'] where responder is True/False.\n",
    "    drugdict : dict\n",
    "        {\n",
    "          patient_id: {\n",
    "            'all_visits': [...],\n",
    "            'drug_administrations': [timestamp1, timestamp2, …]\n",
    "          },\n",
    "          …\n",
    "        }\n",
    "    patient_id : hashable\n",
    "        The ID of the patient to plot.\n",
    "    normalize : bool, default False\n",
    "        If True, divide values by the first measurement within the drug window.\n",
    "    \"\"\"\n",
    "    # 1. Lookup responder status & choose color\n",
    "    resp_map = dict(zip(responsedf['person_id'], responsedf['responder']))\n",
    "    is_resp = resp_map.get(patient_id, False)\n",
    "    color   = 'blue' if is_resp else 'red'\n",
    "    label   = f\"{patient_id} ({'responder' if is_resp else 'non-responder'})\"\n",
    "\n",
    "    # 2. Determine drug window\n",
    "    info = drugdict.get(patient_id, {})\n",
    "    admin_times = pd.to_datetime(\n",
    "        pd.Series(info.get('drug_administrations', [])),\n",
    "        errors='coerce'\n",
    "    ).dropna()\n",
    "    if admin_times.empty:\n",
    "        print(f\"No drug administrations for patient {patient_id}.\")\n",
    "        return\n",
    "    window_start = admin_times.min()\n",
    "    window_end   = admin_times.max()\n",
    "\n",
    "    # 3. Grab & filter measurements\n",
    "    dates = pd.to_datetime(patient_dict[patient_id]['measurement_DATE'])\n",
    "    raw   = np.array(patient_dict[patient_id]['value_as_number'], dtype=float)\n",
    "    mask_time  = (dates >= window_start) & (dates <= window_end)\n",
    "    mask_valid = mask_time & (~np.isnan(raw))\n",
    "    if not mask_valid.any():\n",
    "        print(f\"No measurements for patient {patient_id} in drug window.\")\n",
    "        return\n",
    "    meas_dates = dates[mask_valid]\n",
    "    meas_vals  = raw[mask_valid]\n",
    "\n",
    "    # 4. Normalize if requested (to first in window)\n",
    "    if normalize:\n",
    "        norm_factor = meas_vals[0]\n",
    "        if norm_factor and not np.isnan(norm_factor):\n",
    "            meas_vals = meas_vals / norm_factor\n",
    "\n",
    "    # 5. Plot time series line\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(meas_dates, meas_vals,\n",
    "             color=color, alpha=0.7, linewidth=2,\n",
    "             label=label)\n",
    "\n",
    "    # 6. Mark each drug administration with a green dot on the line\n",
    "    admin_in_window = admin_times[(admin_times >= window_start) & (admin_times <= window_end)]\n",
    "    if not admin_in_window.empty:\n",
    "        x_nums  = mdates.date2num(meas_dates)\n",
    "        y_vals  = meas_vals\n",
    "        admin_nums = mdates.date2num(admin_in_window)\n",
    "        # interpolate y at each admin time\n",
    "        admin_y = np.interp(admin_nums, x_nums, y_vals)\n",
    "        plt.scatter(admin_in_window, admin_y,\n",
    "                    color='green', marker='o',\n",
    "                    label='Drug administration', zorder=5)\n",
    "\n",
    "    # 7. Final touches\n",
    "    plt.xlabel(\"Measurement Date\")\n",
    "    ylabel = \"Normalized Value\" if normalize else \"Value as Number\"\n",
    "    plt.ylabel(ylabel)\n",
    "    title = f\"Patient {patient_id} Time Series\"\n",
    "    if normalize:\n",
    "        title += \" (normalized to first in drug window)\"\n",
    "    plt.title(title)\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_single_patient_with_drug_markers(\n",
    "    filtered_patient_dict,\n",
    "    responder_df,\n",
    "    summary_dict,\n",
    "    patient_id=30116620,\n",
    "    normalize=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bec017-7b65-4205-9158-a35ffc3891cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4f142b-69cc-4553-b863-8d4e3b851c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3887853a-4840-48fd-8b1e-2ccf7fdb3ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd009d22-a037-4019-8e4b-adeb5eef9435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44579c9f-7ffe-4e09-aa1f-7ad9f85b165b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59acc8c4-9e00-4fbf-8e7f-5e8c077fb667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95923c04-ca25-4e93-bf60-aa2fb40f1b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gseapy as gp\n",
    "print(gseapy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227d291c-ab24-4cc2-9d40-60eef5202457",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = gp.get_library_name()\n",
    "names.index('GO_Molecular_Function_2018')\n",
    "names[77:88]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc788a78-0bce-4ff8-adfe-31f8f8f5a94b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## download library or read a .gmt file\n",
    "go_mf = gp.get_library(name='GO_Molecular_Function_2025', organism='Human')\n",
    "go_mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c612a1-8eaa-4df0-8742-1df8c5872617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GO Molecular Function 2023 library\n",
    "go_mf = gp.get_library(name='GO_Molecular_Function_2025', organism='Human')\n",
    "\n",
    "# Convert the library into a more usable format\n",
    "pathway_proteins = []\n",
    "\n",
    "for pathway, proteins in go_mf.items():\n",
    "    pathway_proteins.append({\"Pathway\": pathway, \"Proteins\": proteins})\n",
    "\n",
    "# Optionally, convert the result to a pandas DataFrame for easier viewing and manipulation\n",
    "import pandas as pd\n",
    "\n",
    "pathway_df = pd.DataFrame(pathway_proteins)\n",
    "\n",
    "# Save to a CSV if needed\n",
    "pathway_df.to_csv(\"go_mf_pathways_and_proteins.csv\", index=False)\n",
    "\n",
    "# Display the first few rows\n",
    "pathway_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b9d617-b100-45d3-aa27-26ac15700bda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "actual_prot = pd.read_csv('../all_proteomics_lc_cleaned.csv')\n",
    "# Extract column names that end with \"_protein\"\n",
    "protein_columns = [col for col in actual_prot.columns if col.endswith('_protein')]\n",
    "\n",
    "# Capitalize everything and remove the \"_protein\" suffix\n",
    "background_proteins = [col.replace('_protein', '').upper() for col in protein_columns]\n",
    "\n",
    "# Resulting list of cleaned column names\n",
    "background_proteins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10bb215-d03a-4185-8983-4aa7ff748dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def get_top_bottom_pct(df,\n",
    "                       feature_col: str = 'feature',\n",
    "                       odds_col: str = 'odds_ratio',\n",
    "                       pct: float = 0.10,\n",
    "                       suffix: str = '_prediction'):\n",
    "    \"\"\"\n",
    "    Returns two lists:\n",
    "      - top_pct: the features in the top pct fraction by odds_ratio\n",
    "      - bot_pct: the features in the bottom pct fraction by odds_ratio\n",
    "\n",
    "    Exactly ceil(len(df) * pct) items in each list.\n",
    "    Strips the given suffix from each feature name.\n",
    "    \"\"\"\n",
    "    # how many to take\n",
    "    n = math.ceil(len(df) * pct)\n",
    "\n",
    "    # sort descending for top\n",
    "    top_df = df.sort_values(by=odds_col, ascending=False).head(n)\n",
    "    top_pct = (\n",
    "        top_df[feature_col]\n",
    "        .str.replace(f'{suffix}$', '', regex=True)\n",
    "        .tolist()\n",
    "    )\n",
    "\n",
    "    # sort ascending for bottom\n",
    "    bot_df = df.sort_values(by=odds_col, ascending=True).head(n)\n",
    "    bot_pct = (\n",
    "        bot_df[feature_col]\n",
    "        .str.replace(f'{suffix}$', '', regex=True)\n",
    "        .tolist()\n",
    "    )\n",
    "\n",
    "    return top_pct, bot_pct\n",
    "\n",
    "\n",
    "top10pct, bot10pct = get_top_bottom_pct(coef_df_sorted)\n",
    "print(len(top10pct), len(bot10pct))  # each should be math.ceil(2923*0.1)=293\n",
    "print(\"Top 10% features:\", top10pct)\n",
    "print(\"Bottom 10% features:\", bot10pct)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579c2872-caca-4690-9d67-409fef6608a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backgound only reconigized a gene list input.\n",
    "top10_enr_bg = gp.enrichr(gene_list=top10pct,\n",
    "                 gene_sets=['GO_Molecular_Function_2025'],\n",
    "                 # organism='human', # organism argment is ignored because user input a background\n",
    "                 background=background_proteins,\n",
    "                 outdir=None, # don't write to disk\n",
    "                )\n",
    "\n",
    "top10_enr_bg.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7222ca-85e2-4a4e-8960-091aa8be9b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_enr_bg.results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb29b91-8ac3-42f8-8fb1-9006fc63a091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backgound only reconigized a gene list input.\n",
    "bot10_enr_bg = gp.enrichr(gene_list=bot10pct,\n",
    "                 gene_sets=['GO_Molecular_Function_2025'],\n",
    "                 # organism='human', # organism argment is ignored because user input a background\n",
    "                 background=background_proteins,\n",
    "                 outdir=None, # don't write to disk\n",
    "                )\n",
    "\n",
    "bot10_enr_bg.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad55109-fcee-4367-a7d6-17ea73c80254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gseapy as gp\n",
    "from gseapy.parser import get_library\n",
    "\n",
    "# 2. Load the Enrichr library you care about\n",
    "go_lib = get_library(name='GO_Molecular_Function_2025', organism='Human')\n",
    "\n",
    "# 3. Build the universe of all genes in that library\n",
    "enrichr_genes = set().union(*(set(genes) for genes in go_lib.values()))\n",
    "\n",
    "# 4. Find which of your background genes are missing\n",
    "missing = [g for g in background_proteins if g not in enrichr_genes]\n",
    "\n",
    "print(f\"{len(missing)} genes of your {len(background_proteins)}-gene background were NOT found in GO_Molecular_Function_2025\")\n",
    "print(\"Missing genes:\", missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1a2389-2073-45eb-9170-ceb2bc0bc2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gseapy as gp\n",
    "from gseapy.parser import get_library\n",
    "\n",
    "def load_enrichr_library(lib_name: str, organism: str = 'Human') -> set:\n",
    "    \"\"\"\n",
    "    Download an Enrichr library and return the set of all member genes/IDs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lib_name : str\n",
    "        Name of the Enrichr gene set (e.g. 'GO_Molecular_Function_2025').\n",
    "    organism : str\n",
    "        Organism for the library ('Human' or 'Mouse').\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Set[str]\n",
    "        All gene symbols or Entrez IDs in the library.\n",
    "    \"\"\"\n",
    "    gs_dict = get_library(name=lib_name, organism=organism)\n",
    "    # union all term lists into one flat set\n",
    "    return set().union(*(set(genes) for genes in gs_dict.values()))\n",
    "\n",
    "def is_in_enrichr(gene: str, lib_genes: set) -> bool:\n",
    "    \"\"\"\n",
    "    Case‐insensitively check if `gene` is in the enrichr library set.\n",
    "    \"\"\"\n",
    "    return gene.upper() in {g.upper() for g in lib_genes}\n",
    "\n",
    "# --- Example usage ---\n",
    "\n",
    "# 1. Load your library of interest\n",
    "library_genes = load_enrichr_library('GO_Molecular_Function_2025')\n",
    "\n",
    "# 2. Check one or more genes\n",
    "for test_gene in ['LEU1', 'T1']:\n",
    "    found = is_in_enrichr(test_gene, library_genes)\n",
    "    print(f\"{test_gene}: {'FOUND' if found else 'NOT found'} in GO_Molecular_Function_2025\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512094c1-eac2-4be4-9667-250d232b3573",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# remove the suffix \"_prediction\" if present\n",
    "coef_df_sorted['feature'] = coef_df_sorted['feature'].str.replace(r'_prediction$', '', regex=True)\n",
    "\n",
    "coef_df_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc40a983-6348-4bdb-8204-97e4bd10f9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df_sorted.to_csv('./test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd5ced0-34fe-417e-97d0-e2cd0fe00667",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "davidpython_updated",
   "language": "python",
   "name": "davidpython_updated"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
