{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58b9b54-0b22-43ea-9f26-142a43ae61e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from typing import Dict, Sequence, Optional, Tuple, Iterable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from adjustText import adjust_text\n",
    "from lifelines import CoxPHFitter, KaplanMeierFitter\n",
    "from lifelines.exceptions import ConvergenceError\n",
    "from lifelines.statistics import logrank_test\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    cross_val_score,\n",
    "    learning_curve,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr, spearmanr, linregress, zscore\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "from matplotlib.lines import Line2D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73fe44f-087f-45fd-a922-8e1b3d7f7479",
   "metadata": {},
   "source": [
    "# Train aging clock using measured proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63838a26-5b07-4691-ad6a-7f14186178f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in files\n",
    "measuredprot_train = pd.read_csv('/path/to/measured_proteins/training_split')\n",
    "measuredprot_test = pd.read_csv('/path/to/measured_proteins/test_split')\n",
    "\n",
    "rabitprot_train = pd.read_csv('/path/to/RABIT_proteins/training_split')\n",
    "rabitprot_train.rename(columns={'patient_ids': 'eid'}, inplace=True)\n",
    "rabitprot_train.columns = [col.replace('_prediction', '_protein') if '_prediction' in col else col for col in rabitprot_train.columns]\n",
    "\n",
    "rabitprot_test = pd.read_csv('/path/to/RABIT_proteins/test_split')\n",
    "rabitprot_test.rename(columns={'patient_ids': 'eid'}, inplace=True)\n",
    "rabitprot_test.columns = [col.replace('_prediction', '_protein') if '_prediction' in col else col for col in rabitprot_test.columns]\n",
    "\n",
    "ehr_train = pd.read_csv('/path/to/EHR ehr representation/training_split')\n",
    "ehr_train.drop(columns=[\"labeling_time\"], inplace=True)\n",
    "ehr_train.rename(columns={\"patient_ids\": \"eid\"}, inplace=True)\n",
    "\n",
    "ehr_test = pd.read_csv('/path/to/EHR ehr representation/test_split')\n",
    "ehr_test.drop(columns=[\"labeling_time\"], inplace=True)\n",
    "ehr_test.rename(columns={\"patient_ids\": \"eid\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0614c00a-bde8-4fa3-b8f0-6bd503220477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata dataframe with columns \"patient_id\" (patient identifier), \"prediction_time\" (date of RABIT protein generation),\n",
    "## \"birth_datetime\" (patient birthday), and \"age_at_prediction\" (patient age at date of RABIT protein generation)\n",
    "age_df = pd.read_csv('./info_files/all_ukbb_patients_ages_at_proteomics_collection.csv')\n",
    "age_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dc7e74-a67f-4c26-acf5-9495a555e32f",
   "metadata": {},
   "source": [
    "### organ specific protein dataframe downloaded from https://www.biorxiv.org/content/10.1101/2024.06.07.597771v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8d4b25-d9c0-42df-88d0-132903bcf61f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "organ_prot = pd.read_csv('/path/to/organ_specific_proteins/organ_specific_proteins_for_aging.csv')\n",
    "organ_prot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b4c8c8-b3ea-4e76-abd5-9fe6cde1a770",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Conver to dictionary\n",
    "def dataframe_to_dict_unique(df):\n",
    "    result = {}\n",
    "    for col in df.columns:\n",
    "        # Get non-NaN values from the column as a list.\n",
    "        values = df[col].dropna().tolist()\n",
    "        # Remove duplicates while preserving the order.\n",
    "        unique_values = list(dict.fromkeys(values))\n",
    "        result[col] = unique_values\n",
    "    return result\n",
    "\n",
    "organ_prot_cleaned_dict = dataframe_to_dict_unique(organ_prot)\n",
    "organ_prot_cleaned_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c74f6ee-cf10-45f3-8117-b374c0a89100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset proteins by organspecific protein list\n",
    "def subset_protdf_by_organkey(result_dict, protdf, organkey):\n",
    "    # Retrieve the protein list for the specified organkey.\n",
    "    protein_list = result_dict.get(organkey, [])\n",
    "    \n",
    "    # Count how many entries are multiprote strings (i.e. contain a dot).\n",
    "    multiprote_count = sum(1 for x in protein_list if \".\" in x)\n",
    "    \n",
    "    # Split any multiprote strings into individual protein names.\n",
    "    individual_proteins = []\n",
    "    for prot in protein_list:\n",
    "        if \".\" in prot:\n",
    "            parts = prot.split(\".\")\n",
    "            individual_proteins.extend(parts)\n",
    "        else:\n",
    "            individual_proteins.append(prot)\n",
    "    \n",
    "    total_individuals = len(individual_proteins)\n",
    "\n",
    "    col_mapping = {}\n",
    "    for col in protdf.columns:\n",
    "        if col in ['eid', 'age_at_prediction']:\n",
    "            continue\n",
    "        if col.endswith('_protein'):\n",
    "            cleaned = col[:-8]  # Remove '_protein'\n",
    "        else:\n",
    "            cleaned = col\n",
    "        # Use lowercase for matching\n",
    "        col_mapping[cleaned.lower()] = col\n",
    "\n",
    "    # Search for matches and record any protein names that aren't found.\n",
    "    matched_columns = []\n",
    "    found_count = 0\n",
    "    not_found = []\n",
    "    \n",
    "    for prot in individual_proteins:\n",
    "        prot_lower = prot.lower()\n",
    "        if prot_lower in col_mapping:\n",
    "            matched_columns.append(col_mapping[prot_lower])\n",
    "            found_count += 1\n",
    "        else:\n",
    "            not_found.append(prot)\n",
    "    \n",
    "    # Remove duplicate matched columns (preserving order) and always include the mandatory columns.\n",
    "    final_cols = ['eid', 'age_at_prediction'] + list(dict.fromkeys(matched_columns))\n",
    "    \n",
    "    # Subset the DataFrame.\n",
    "    subset_df = protdf[final_cols].copy()\n",
    "    \n",
    "    # Print the summary information.\n",
    "    print(f\"Out of {total_individuals} individual protein names from '{organkey}', {found_count} were found in protdf.\")\n",
    "    print(f\"There were {multiprote_count} multiprote strings in '{organkey}' to begin with.\")\n",
    "    \n",
    "    # Remove duplicates from not_found (preserving order) before printing.\n",
    "    not_found_unique = list(dict.fromkeys(not_found))\n",
    "    if not_found_unique:\n",
    "        print(\"The following protein names were not found in protdf:\")\n",
    "        for name in not_found_unique:\n",
    "            print(name)\n",
    "    else:\n",
    "        print(\"All protein names were found in protdf.\")\n",
    "    \n",
    "    return subset_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad80a64e-a774-48a8-80f4-e3f6c4543c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "measuredprot_train_training = pd.merge(\n",
    "    measuredprot_train,\n",
    "    age_df[['patient_id', 'age_at_prediction']],  # Use a list for column selection\n",
    "    left_on='eid',\n",
    "    right_on='patient_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "measuredprot_train_training.drop(columns='patient_id', inplace=True)\n",
    "\n",
    "\n",
    "measuredprot_test_test = pd.merge(\n",
    "    measuredprot_test,\n",
    "    age_df[['patient_id', 'age_at_prediction']],  # Use a list for column selection\n",
    "    left_on='eid',\n",
    "    right_on='patient_id',\n",
    "    how='left'\n",
    ")\n",
    "measuredprot_test_test.drop(columns='patient_id', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a00790-a4e6-42f5-86be-79199adba31c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve_and_figures(currentorgan, Xtrain, ytrain, Xtest, ytest, ypred, organdictionary, best_alpha, modelpath):            \n",
    "    # Directory to save plots\n",
    "    plot_dir = f\"{modelpath}/{currentorgan}_model\"\n",
    "\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "    \n",
    "    # Generate Learning Curve\n",
    "    print(\"Generating Learning Curve...\")\n",
    "    train_sizes, train_scores, val_scores = learning_curve(\n",
    "        Lasso(alpha=best_alpha, random_state=42, max_iter=5000),\n",
    "        Xtrain,\n",
    "        ytrain,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        train_sizes=np.linspace(0.1, 1.0, 10)\n",
    "    )\n",
    "    \n",
    "    # Calculate mean and standard deviation of scores\n",
    "    train_mean = -train_scores.mean(axis=1)  # Negate to get positive MSE\n",
    "    train_std = train_scores.std(axis=1)\n",
    "    val_mean = -val_scores.mean(axis=1)\n",
    "    val_std = val_scores.std(axis=1)\n",
    "    \n",
    "    # Plot learning curve and show in Jupyter Notebook\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_sizes, train_mean, label='Training Error', marker='o')\n",
    "    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2)\n",
    "    plt.plot(train_sizes, val_mean, label='Validation Error', marker='o')\n",
    "    plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.2)\n",
    "    plt.xlabel('Training Set Size')\n",
    "    plt.ylabel('Mean Squared Error')\n",
    "    plt.title('Learning Curve for Lasso Regression')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    # Save the learning curve as an SVG file\n",
    "    learning_curve_svg_path = os.path.join(plot_dir, 'learning_curve.svg')\n",
    "    plt.savefig(learning_curve_svg_path, format='svg')\n",
    "    print(f\"{currentorgan} Learning curve saved to {learning_curve_svg_path}\")\n",
    "    \n",
    "    # Show plot in the notebook\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # 1. Calculate Pearson Correlation\n",
    "    pearson_corr, p_value = pearsonr(ytest, ypred)\n",
    "    print(f\"Pearson Correlation: {pearson_corr:.4f} (p-value: {p_value:.4e})\")\n",
    "\n",
    "    \n",
    "    # 2. Generate Predicted vs Actual Values Plot\n",
    "    print(\"Generating Predicted vs Actual Values Plot...\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(ytest, ypred, alpha=0.6, label='Predictions')\n",
    "    plt.plot([ytest.min(), ytest.max()], [ytest.min(), ytest.max()], 'r--', label='Perfect Prediction')\n",
    "    plt.xlabel('Actual Age')\n",
    "    plt.ylabel('Predicted Age')\n",
    "    plt.title(f'{currentorgan} Predicted vs Actual Values')\n",
    "    \n",
    "    # Display the Pearson correlation value on the graph\n",
    "    plt.text(0.05, 0.95, f'Pearson r = {pearson_corr:.4f}', transform=plt.gca().transAxes,\n",
    "             fontsize=14, verticalalignment='top')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    # Save the plot as an SVG file\n",
    "    predicted_vs_actual_svg_path = os.path.join(plot_dir, 'predicted_vs_actual.svg')\n",
    "    plt.savefig(predicted_vs_actual_svg_path, format='svg')\n",
    "    print(f\"{currentorgan} Predicted vs Actual plot saved to {predicted_vs_actual_svg_path}\")\n",
    "    \n",
    "    # Show plot in the notebook\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def train_organspecific_model(traindf, testdf, organdictionary, modelpath):\n",
    "    organlist = organdictionary.keys()\n",
    "    for organ in organlist:\n",
    "        # Subset dataframes\n",
    "        measuredprot_train_training_organ = subset_protdf_by_organkey(organdictionary, traindf, organ)\n",
    "        measuredprot_test_test_organ = subset_protdf_by_organkey(organdictionary, testdf, organ)\n",
    "\n",
    "        # Clean data and standardize\n",
    "        X_train = measuredprot_train_training_organ.drop(columns=['eid', 'age_at_prediction'])\n",
    "        y_train = measuredprot_train_training_organ['age_at_prediction']\n",
    "        print(f\"{organ}: {len(X_train.columns)} features — first five:\",\n",
    "        X_train.columns[:5].tolist())\n",
    "\n",
    "        X_test = measuredprot_test_test_organ.drop(columns=['eid', 'age_at_prediction'])\n",
    "        y_test = measuredprot_test_test_organ['age_at_prediction']\n",
    "\n",
    "        imputer = SimpleImputer(strategy='mean')  # Replace missing values with the mean\n",
    "        X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "        X_test = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "        X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "        \n",
    "        # Hyperparameter tuning\n",
    "        alphas = np.logspace(-2, 1, 20)  # Test 20 values instead of 50\n",
    "        best_alpha = None\n",
    "        best_score = -float('inf')\n",
    "        \n",
    "        print(\"Starting Lasso hyperparameter tuning...\")\n",
    "        for alpha in tqdm(alphas, desc=\"Tuning alpha\"):\n",
    "            model = Lasso(alpha=alpha, random_state=42, max_iter=5000)  # Increased max_iter\n",
    "            scores = cross_val_score(model, X_train, y_train, cv=3, scoring='r2') # Can potentially change this scoring function\n",
    "            mean_score = scores.mean()\n",
    "        \n",
    "            if mean_score > best_score:\n",
    "                best_score = mean_score\n",
    "                best_alpha = alpha\n",
    "        \n",
    "        print(f\"Best alpha: {best_alpha}\")\n",
    "        print(f\"Best cross-validated R^2: {best_score}\")\n",
    "        \n",
    "        # Train final model (best alpha)\n",
    "        lasso = Lasso(alpha=best_alpha, random_state=42, max_iter=5000)\n",
    "        lasso.fit(X_train, y_train)\n",
    "        \n",
    "        # Test on test set\n",
    "        y_pred = lasso.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"Mean Squared Error (Test Set): {mse}\")\n",
    "        print(f\"R^2 Score (Test Set): {r2}\")\n",
    "        \n",
    "        # Save model and components\n",
    "        model_dir = f\"{modelpath}/{organ}_model\"\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        model_filename = os.path.join(model_dir, 'lasso_age_predictor.pkl')\n",
    "        joblib.dump(lasso, model_filename)\n",
    "        print(f\"Model saved to {model_filename}\")\n",
    "        \n",
    "        # Save the imputer\n",
    "        imputer_filename = os.path.join(model_dir, 'imputer.pkl')\n",
    "        joblib.dump(imputer, imputer_filename)\n",
    "        print(f\"Imputer saved to {imputer_filename}\")\n",
    "        \n",
    "        # Save the scaler\n",
    "        scaler_filename = os.path.join(model_dir, 'scaler.pkl')\n",
    "        joblib.dump(scaler, scaler_filename)\n",
    "        print(f\"Scaler saved to {scaler_filename}\")\n",
    "        \n",
    "        # Feature importance analysis\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'Feature': X_train.columns,\n",
    "            'Coefficient': lasso.coef_\n",
    "        })\n",
    "        \n",
    "        important_features = feature_importance[feature_importance['Coefficient'] != 0]\n",
    "        print(\"Important Features with Non-Zero Coefficients:\")\n",
    "        print(important_features)\n",
    "        important_features_filename = os.path.join(model_dir, 'important_features.csv')\n",
    "        important_features.to_csv(important_features_filename, index=False)\n",
    "        print(f\"Important features saved to {important_features_filename}\")\n",
    "\n",
    "        print(f\"Creating learning curves and figures for {organ}\")\n",
    "        plot_learning_curve_and_figures(organ, X_train, y_train, X_test, y_test, y_pred, organdictionary, best_alpha, modelpath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ff951b-c8f9-4bf9-8a97-acb9a84f45bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "train_organspecific_model(measuredprot_train_training, measuredprot_test_test, organ_prot_cleaned_dict, \n",
    "                          modelpath='aging_clock_model_measuredprot_organ_specific')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41470825-4e35-4b2e-8dd1-fc1337753799",
   "metadata": {},
   "source": [
    "# EHR aging clock training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ebe870-9d73-4580-a16a-b9cbd463e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_train_training = pd.merge(\n",
    "    ehr_train,\n",
    "    age_df[['patient_id', 'age_at_prediction']],  # Use a list for column selection\n",
    "    left_on='eid',\n",
    "    right_on='patient_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "ehr_train_training.drop(columns='patient_id', inplace=True)\n",
    "\n",
    "\n",
    "ehr_test_test = pd.merge(\n",
    "    ehr_test,\n",
    "    age_df[['patient_id', 'age_at_prediction']],  # Use a list for column selection\n",
    "    left_on='eid',\n",
    "    right_on='patient_id',\n",
    "    how='left'\n",
    ")\n",
    "ehr_test_test.drop(columns='patient_id', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a824ff-c91e-46a8-891c-9abeece73c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data and standardize data\n",
    "X_train = ehr_train_training.drop(columns=['eid', 'age_at_prediction'])\n",
    "y_train = ehr_train_training['age_at_prediction']\n",
    "\n",
    "X_test = ehr_test_test.drop(columns=['eid', 'age_at_prediction'])\n",
    "y_test = ehr_test_test['age_at_prediction']\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# Hyperparameter tuning for LASSO (conducted in original study)\n",
    "alphas = np.logspace(-2, 1, 20)  # Test 20 values instead of 50\n",
    "best_alpha = None\n",
    "best_score = -float('inf')\n",
    "\n",
    "print(\"Starting Lasso hyperparameter tuning...\")\n",
    "for alpha in tqdm(alphas, desc=\"Tuning alpha\"):\n",
    "    model = Lasso(alpha=alpha, random_state=42, max_iter=5000)  # Increased max_iter\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring='r2') # Can potentially change this scoring function\n",
    "    mean_score = scores.mean()\n",
    "\n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_alpha = alpha\n",
    "\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "print(f\"Best cross-validated R^2: {best_score}\")\n",
    "\n",
    "# Train final model (best alpha)\n",
    "lasso = Lasso(alpha=best_alpha, random_state=42, max_iter=5000)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Test on hold-out test set\n",
    "y_pred = lasso.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (Test Set): {mse}\")\n",
    "print(f\"R^2 Score (Test Set): {r2}\")\n",
    "\n",
    "# Save model components\n",
    "model_dir = 'aging_clock_model_ehr_hamilton'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "model_filename = os.path.join(model_dir, 'lasso_age_predictor.pkl')\n",
    "joblib.dump(lasso, model_filename)\n",
    "print(f\"Model saved to {model_filename}\")\n",
    "\n",
    "imputer_filename = os.path.join(model_dir, 'imputer.pkl')\n",
    "joblib.dump(imputer, imputer_filename)\n",
    "print(f\"Imputer saved to {imputer_filename}\")\n",
    "\n",
    "scaler_filename = os.path.join(model_dir, 'scaler.pkl')\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "print(f\"Scaler saved to {scaler_filename}\")\n",
    "\n",
    "# Identify feature importances\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': lasso.coef_\n",
    "})\n",
    "\n",
    "important_features = feature_importance[feature_importance['Coefficient'] != 0]\n",
    "print(\"Important Features with Non-Zero Coefficients:\")\n",
    "print(important_features)\n",
    "\n",
    "# Save important features\n",
    "important_features_filename = os.path.join(model_dir, 'important_features.csv')\n",
    "important_features.to_csv(important_features_filename, index=False)\n",
    "print(f\"Important features saved to {important_features_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4aeeb7-41dd-47bd-867e-9ef4f0f78b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_age_clock_model(input_data, model_dir, suffix):\n",
    "    # Load the saved model, imputer, and scaler\n",
    "    lasso = joblib.load(os.path.join(model_dir, 'lasso_age_predictor.pkl'))\n",
    "    imputer = joblib.load(os.path.join(model_dir, 'imputer.pkl'))\n",
    "    scaler = joblib.load(os.path.join(model_dir, 'scaler.pkl'))\n",
    "    \n",
    "    # Separate features and target from new data\n",
    "    X_new = input_data.drop(columns=['eid', 'age_at_prediction'])\n",
    "    y_new = input_data['age_at_prediction']\n",
    "    \n",
    "    # Handle missing values in new data\n",
    "    X_new = pd.DataFrame(imputer.transform(X_new), columns=X_new.columns)\n",
    "    \n",
    "    # Standardize features in new data\n",
    "    X_new = pd.DataFrame(scaler.transform(X_new), columns=X_new.columns)\n",
    "    \n",
    "    # Make predictions on the new data\n",
    "    y_pred_new = lasso.predict(X_new)\n",
    "    \n",
    "    # Create a DataFrame with the results\n",
    "    result_df = pd.DataFrame({\n",
    "        'eid': input_data['eid'],\n",
    "        'actual_age': y_new,  # actual age\n",
    "        f'predicted_age_{suffix}': y_pred_new  # predicted age with suffix\n",
    "    })\n",
    "    \n",
    "    # Evaluate the model on the new dataset\n",
    "    mse_new = mean_squared_error(y_new, y_pred_new)\n",
    "    r2_new = r2_score(y_new, y_pred_new)\n",
    "    \n",
    "    print(f\"Mean Squared Error (New Data): {mse_new}\")\n",
    "    print(f\"R^2 Score (New Data): {r2_new}\")\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "\n",
    "\n",
    "ehr_pred = run_age_clock_model(ehr_test_test, model_dir='aging_clock_model_ehr', suffix='ehr')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fdc9c1-d2bf-4ed3-ae39-be1522dd799c",
   "metadata": {},
   "source": [
    "# Calculate protein age gaps for RABIT and measured proteins using trained protein clock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627214e4-541c-4af0-ac80-ade689e6dbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_age_clock_model(input_data, parent_model_dir, suffix, orgdict):\n",
    "    results = {}\n",
    "    for subdir in os.listdir(parent_model_dir):\n",
    "        full_model_dir = os.path.join(parent_model_dir, subdir)\n",
    "        if not os.path.isdir(full_model_dir):\n",
    "            continue\n",
    "        \n",
    "        # Derive the organ name (assuming subdirectory names like 'heart_model')\n",
    "        organ_name = subdir.replace('_model', '')\n",
    "        print(f\"\\n=== Processing {organ_name} ===\")\n",
    "        input_data_subset = subset_protdf_by_organkey(orgdict, input_data, organ_name)\n",
    "        if input_data_subset.empty:\n",
    "            print(f\"No data for organ {organ_name}. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Load the saved model, imputer, and scaler for the current organ\n",
    "            model_path = os.path.join(full_model_dir, 'lasso_age_predictor.pkl')\n",
    "            imputer_path = os.path.join(full_model_dir, 'imputer.pkl')\n",
    "            scaler_path = os.path.join(full_model_dir, 'scaler.pkl')\n",
    "            \n",
    "            lasso = joblib.load(model_path)\n",
    "            imputer = joblib.load(imputer_path)\n",
    "            scaler = joblib.load(scaler_path)\n",
    "            print(f\"Loaded artifacts for {organ_name} from {full_model_dir}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model artifacts for {organ_name}: {e}\")\n",
    "            continue\n",
    "        try:\n",
    "            X_new = input_data_subset.drop(columns=['eid', 'age_at_prediction'])\n",
    "            y_new = input_data_subset['age_at_prediction']\n",
    "            \n",
    "            # Preprocess new data: impute then scale\n",
    "            X_new_imputed = pd.DataFrame(imputer.transform(X_new), columns=X_new.columns)\n",
    "            X_new_scaled = pd.DataFrame(scaler.transform(X_new_imputed), columns=X_new_imputed.columns)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing input data for {organ_name}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Make predictions\n",
    "            y_pred_new = lasso.predict(X_new_scaled)\n",
    "            mse_new = mean_squared_error(y_new, y_pred_new)\n",
    "            r2_new = r2_score(y_new, y_pred_new)\n",
    "            print(f\"Results for {organ_name}: MSE = {mse_new:.4f}, R² = {r2_new:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during prediction for {organ_name}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        result_df = pd.DataFrame({\n",
    "            'eid': input_data_subset['eid'],\n",
    "            'actual_age': y_new,\n",
    "            f'predicted_age_{suffix}': y_pred_new\n",
    "        })\n",
    "        \n",
    "        results[organ_name] = result_df\n",
    "    \n",
    "    return results\n",
    "\n",
    "rabit_results = run_age_clock_model(\n",
    "    input_data=testsplit_rabit_test,\n",
    "    parent_model_dir='aging_clock_model_measuredprot_organ_specific',\n",
    "    suffix='rabit',\n",
    "    orgdict=organ_prot_cleaned_dict\n",
    ")\n",
    "\n",
    "measuredprot_results = run_age_clock_model(\n",
    "    input_data=testsplit_measuredprot_test,\n",
    "    parent_model_dir='aging_clock_model_measuredprot_organ_specific',\n",
    "    suffix='measuredprot',\n",
    "    orgdict=organ_prot_cleaned_dict\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f30753-e2a2-4c06-883b-a9ad3dd607bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize all results (ehr, RABIT, Measured) into one dictionary for downstream processing\n",
    "\n",
    "tissue_keys = ['Adipose', 'Artery', 'Brain', 'Heart', 'Immune', 'Intestine',\n",
    "               'Kidney', 'Liver', 'Lung', 'Muscle', 'Pancreas', 'Organismal', 'Conventional']\n",
    "\n",
    "# Create a dictionary of dataframes by copying the original df for each tissue\n",
    "ehr_results = {tissue: ehr_pred.copy() for tissue in tissue_keys}\n",
    "\n",
    "# Initialize a dictionary to store the merged dataframes for each organ\n",
    "age_gap_dfs = {}\n",
    "\n",
    "# Loop through each organ available in measuredprot_results\n",
    "for organ, measuredprot_pred in measuredprot_results.items():\n",
    "    if organ in rabit_results:\n",
    "        rabit_pred_clean = rabit_results[organ].drop(columns=['actual_age'])\n",
    "        ehr_results_clean = ehr_results[organ].drop(columns=['actual_age'])\n",
    "        merged_df = pd.merge(measuredprot_pred, rabit_pred_clean, on='eid', how='inner')\n",
    "        merged_df2 = pd.merge(merged_df, ehr_results_clean, on='eid', how='inner')\n",
    "\n",
    "        # Store the merged dataframe in the dictionary, keyed by the organ name\n",
    "        age_gap_dfs[organ] = merged_df2\n",
    "\n",
    "age_gap_dfs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7345c74f-3a00-44c4-a86c-d5d6e6c70f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate age gaps\n",
    "def calculate_age_gaps(agegapdf):\n",
    "\n",
    "    # Make a copy of the DataFrame to avoid modifying the original data\n",
    "    df = agegapdf.copy()\n",
    "\n",
    "    # Ensure that the necessary columns are present\n",
    "    required_columns = [\n",
    "        \"eid\",\n",
    "        \"actual_age\",\n",
    "        \"predicted_age_measuredprot\",\n",
    "        \"predicted_age_rabit\",\n",
    "        \"predicted_age_ehr\"\n",
    "    ]\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Missing required column: '{col}'\")\n",
    "\n",
    "    # Define a helper function to compute smoothed predicted age using LOESS\n",
    "    def compute_smoothed_pred_age(actual_age, pred_age, frac=2/3):\n",
    "\n",
    "        # Drop any rows with missing values in actual_age or pred_age\n",
    "        valid_idx = actual_age.notna() & pred_age.notna()\n",
    "        actual_age_valid = actual_age[valid_idx]\n",
    "        pred_age_valid = pred_age[valid_idx]\n",
    "\n",
    "        if len(actual_age_valid) == 0:\n",
    "            raise ValueError(\"No valid data points available for LOESS fitting.\")\n",
    "\n",
    "        # Sort the data by actual_age\n",
    "        sorted_indices = actual_age_valid.argsort()\n",
    "        sorted_age = actual_age_valid.iloc[sorted_indices]\n",
    "        sorted_pred = pred_age_valid.iloc[sorted_indices]\n",
    "\n",
    "        # Fit LOESS using statsmodels' lowess function\n",
    "        lowess_results = sm.nonparametric.lowess(\n",
    "            endog=sorted_pred,\n",
    "            exog=sorted_age,\n",
    "            frac=frac,\n",
    "            return_sorted=True\n",
    "        )\n",
    "\n",
    "        # Extract the smoothed predicted ages and the corresponding ages\n",
    "        smoothed_age = lowess_results[:, 0]\n",
    "        smoothed_pred = lowess_results[:, 1]\n",
    "\n",
    "        # Interpolate the smoothed predicted ages for the original actual_age\n",
    "        smoothed_pred_age = np.interp(\n",
    "            actual_age,\n",
    "            smoothed_age,\n",
    "            smoothed_pred,\n",
    "            left=np.nan,  \n",
    "            right=np.nan  \n",
    "        )\n",
    "\n",
    "        return smoothed_pred_age\n",
    "\n",
    "    # Calculate smoothed predicted ages and age gaps for real proteins\n",
    "    df['smoothed_pred_measuredprot'] = compute_smoothed_pred_age(\n",
    "        actual_age=df['actual_age'],\n",
    "        pred_age=df['predicted_age_measuredprot'],\n",
    "        frac=2/3\n",
    "    )\n",
    "    df['age_gap_measuredprot'] = df['predicted_age_measuredprot'] - df['smoothed_pred_measuredprot']\n",
    "\n",
    "    # Calculate smoothed predicted ages and age gaps for synthetic proteins\n",
    "    df['smoothed_pred_rabit'] = compute_smoothed_pred_age(\n",
    "        actual_age=df['actual_age'],\n",
    "        pred_age=df['predicted_age_rabit'],\n",
    "        frac=2/3\n",
    "    )\n",
    "    df['age_gap_rabit'] = df['predicted_age_rabit'] - df['smoothed_pred_rabit']\n",
    "\n",
    "    # Calculate smoothed predicted ages and age gaps for ehr proteins\n",
    "    df['smoothed_pred_ehr'] = compute_smoothed_pred_age(\n",
    "        actual_age=df['actual_age'],\n",
    "        pred_age=df['predicted_age_ehr'],\n",
    "        frac=2/3\n",
    "    )\n",
    "    df['age_gap_ehr'] = df['predicted_age_ehr'] - df['smoothed_pred_ehr']\n",
    "\n",
    "    # Calculate Z-scores for each age gap\n",
    "    df['age_gap_measuredprot_zscore'] = (df['age_gap_measuredprot'] - df['age_gap_measuredprot'].mean()) / df['age_gap_measuredprot'].std(ddof=0)\n",
    "    df['age_gap_rabit_zscore'] = (df['age_gap_rabit'] - df['age_gap_rabit'].mean()) / df['age_gap_rabit'].std(ddof=0)\n",
    "    df['age_gap_ehr_zscore'] = (df['age_gap_ehr'] - df['age_gap_ehr'].mean()) / df['age_gap_ehr'].std(ddof=0)\n",
    "\n",
    "    df.drop(['smoothed_pred_measuredprot', 'smoothed_pred_rabit', 'smoothed_pred_ehr'], axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def calculate_age_gaps_for_dict(dict_of_dfs):\n",
    "    processed_dict = {}\n",
    "    for tissue, df in dict_of_dfs.items():\n",
    "        # Process each dataframe (using a copy to avoid modifying the original)\n",
    "        processed_dict[tissue] = calculate_age_gaps(df.copy())\n",
    "    return processed_dict\n",
    "\n",
    "# Calculate gaps (LOESS regression, same as original study)\n",
    "age_gap_simple_dfs = calculate_age_gaps_for_dict(age_gap_dfs)\n",
    "age_gap_simple_dfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c3870f-9fca-4360-bd65-7be15334240a",
   "metadata": {},
   "source": [
    "# Calculating disease hazard ratios for each organ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1107628a-4f00-49dc-b334-8872f8ad99b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "persondf = pd.read_csv('/path/to/person omop table')\n",
    "\n",
    "# Create sex dataframe\n",
    "subset_df = persondf[['person_id', 'gender_concept_id']]\n",
    "\n",
    "renamed_df = subset_df.rename(columns={\n",
    "    'person_id': 'eid',\n",
    "    'gender_concept_id': 'sex'\n",
    "})\n",
    "\n",
    "gender_mapping = {\n",
    "    8507: 'male',\n",
    "    8532: 'female'\n",
    "}\n",
    "renamed_df['sex'] = renamed_df['sex'].map(gender_mapping)\n",
    "renamed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b22c96-6327-42d7-adc9-ee176f54ae28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the merged covariates for each organ\n",
    "covariates_dfs = {}\n",
    "\n",
    "# Loop over each organ-specific DataFrame in age_gap_simple_dfs\n",
    "for organ, age_gap_df in age_gap_simple_dfs.items():\n",
    "    # Merge the renamed_df with the organ-specific age gap DataFrame on 'eid'\n",
    "    covariates = pd.merge(\n",
    "        renamed_df,\n",
    "        age_gap_df,\n",
    "        on='eid',\n",
    "        how='inner'\n",
    "    )\n",
    "    covariates_dfs[organ] = covariates\n",
    "covariates_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39374b97-6c25-4edb-9d76-213c074e13bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read disease labels. also need age_df from above\n",
    "master_label = pd.read_csv('/path/to/disease diagnosis labels/from original paper (see biorxiv link above)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c379b7e-3224-4322-87c9-dcf2325f1930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for cox analysis\n",
    "import pandas as pd\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines.exceptions import ConvergenceError\n",
    "\n",
    "def perform_multiple_cox_models_individual_censor_dates(\n",
    "    covdf_dict: dict,   # Dictionary of organ-specific covariate DataFrames, keyed by organ name\n",
    "    target_df: pd.DataFrame,\n",
    "    agedf: pd.DataFrame,\n",
    "    disease_columns: list,\n",
    "    covariate_columns: list = ['sex', 'actual_age'],\n",
    "    categorical_covariates: list = ['sex'],\n",
    "    censor_date: str = None,\n",
    "    censor_date_df: pd.DataFrame = None,   # New: DataFrame with individual censor dates.\n",
    "    default_censor_date: str = None,         # Fallback censor date for samples missing one.\n",
    "    date_format: str = '%Y-%m-%d'\n",
    "):\n",
    "    results_dict = {}\n",
    "    merged_dfs_dict = {}\n",
    "    \n",
    "    target_df = target_df.rename(columns={'person_id': 'eid'})\n",
    "    agedf = agedf.rename(columns={'patient_id': 'eid'})\n",
    "    target_df[disease_columns] = target_df[disease_columns].replace(0, pd.NaT)\n",
    "    for disease in disease_columns:\n",
    "        target_df[disease] = pd.to_datetime(target_df[disease], format=date_format, errors='coerce')\n",
    "    \n",
    "    # Convert prediction_time to datetime\n",
    "    agedf['prediction_time'] = pd.to_datetime(agedf['prediction_time'], format=date_format, errors='coerce')\n",
    "    \n",
    "    # Individual censor dates from UK Biobank (varies by patient geographic location)\n",
    "    if censor_date_df is not None:\n",
    "        censor_date_df = censor_date_df.rename(columns={'patient_id': 'eid'})\n",
    "        censor_date_df['censor_date'] = pd.to_datetime(censor_date_df['censor_date'], format=date_format, errors='coerce')\n",
    "\n",
    "    # Loop over each organ\n",
    "    for organ, covdf in covdf_dict.items():\n",
    "        print(f\"\\nProcessing organ: {organ}\")\n",
    "        merged_df = pd.merge(covdf, agedf, on='eid', how='left')\n",
    "        merged_df = pd.merge(merged_df, target_df, on='eid', how='left')\n",
    "        if censor_date_df is not None:\n",
    "            merged_df = pd.merge(merged_df, censor_date_df[['eid', 'censor_date']], on='eid', how='left')\n",
    "            # If a default censor date is provided, fill missing values\n",
    "            if default_censor_date:\n",
    "                default_censor_datetime = pd.to_datetime(default_censor_date, format=date_format, errors='coerce')\n",
    "                merged_df['censor_date'] = merged_df['censor_date'].fillna(default_censor_datetime)\n",
    "            else:\n",
    "                # If some rows are missing censor_date, raise an error.\n",
    "                if merged_df['censor_date'].isnull().any():\n",
    "                    raise ValueError(f\"Missing censor dates.\")\n",
    "        else:\n",
    "            if censor_date:\n",
    "                common_censor_datetime = pd.to_datetime(censor_date, format=date_format, errors='coerce')\n",
    "            else:\n",
    "                # Use the maximum diagnosis date across all diseases as censor_date\n",
    "                max_dates = target_df[disease_columns].max().max()\n",
    "                common_censor_datetime = max_dates + pd.Timedelta(days=1)  \n",
    "            merged_df['censor_date'] = common_censor_datetime\n",
    "        \n",
    "        merged_dfs_dict[organ] = merged_df\n",
    "    \n",
    "        # unique_censor_dates = merged_df['censor_date'].unique()\n",
    "        # print(f\"Censor date(s) for {organ}: {unique_censor_dates}\")\n",
    "        \n",
    "        organ_results = {}\n",
    "        \n",
    "        # looping through disease per organ\n",
    "        for disease in disease_columns:\n",
    "            print(f\"\\nAnalyzing disease: {disease} for organ: {organ}\")\n",
    "            disease_df = merged_df[['eid', 'prediction_time', disease, 'censor_date'] + covariate_columns].copy()\n",
    "            disease_df['diagnosis_date'] = pd.to_datetime(disease_df[disease], format=date_format, errors='coerce')\n",
    "            disease_df['event_occurred'] = (~disease_df['diagnosis_date'].isna()).astype(int)\n",
    "            # Exclude prevalent cases: those with diagnosis_date <= prediction_time\n",
    "            disease_df['prevalent'] = disease_df['diagnosis_date'] <= disease_df['prediction_time']\n",
    "            disease_df = disease_df[~disease_df['prevalent']].copy()\n",
    "            \n",
    "            disease_df['time_to_event'] = (disease_df['diagnosis_date'] - disease_df['prediction_time']).dt.days\n",
    "            disease_df.loc[disease_df['event_occurred'] == 0, 'time_to_event'] = (\n",
    "                disease_df.loc[disease_df['event_occurred'] == 0, 'censor_date'] -\n",
    "                disease_df.loc[disease_df['event_occurred'] == 0, 'prediction_time']\n",
    "            ).dt.days\n",
    "            disease_df['event_occurred'] = disease_df['diagnosis_date'].notna().astype(int)\n",
    "            \n",
    "            # columsn for modeling\n",
    "            model_df = disease_df[['time_to_event', 'event_occurred'] + covariate_columns].copy()\n",
    "            if categorical_covariates:\n",
    "                model_df = pd.get_dummies(model_df, columns=categorical_covariates, drop_first=True)\n",
    "            model_df = model_df.dropna()\n",
    "            \n",
    "            # Initialize and fit the Cox proportional hazards model\n",
    "            cph = CoxPHFitter()\n",
    "            formula = \" + \".join([col for col in model_df.columns if col not in ['time_to_event', 'event_occurred']])\n",
    "            try:\n",
    "                cph.fit(model_df, duration_col='time_to_event', event_col='event_occurred', formula=formula)\n",
    "                print(cph.summary)\n",
    "                organ_results[disease] = {\n",
    "                    'model': cph,\n",
    "                    'summary': cph.summary\n",
    "                }\n",
    "            except ConvergenceError:\n",
    "                print(f\"Model for {disease} in organ {organ} did not converge.\")\n",
    "                organ_results[disease] = {\n",
    "                    'model': None,\n",
    "                    'summary': \"Model did not converge.\"\n",
    "                }\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while fitting the model for {disease} in organ {organ}: {e}\")\n",
    "                organ_results[disease] = {\n",
    "                    'model': None,\n",
    "                    'summary': f\"Error: {e}\"\n",
    "                }\n",
    "        \n",
    "        results_dict[organ] = organ_results\n",
    "\n",
    "    return results_dict, merged_dfs_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def aggregate_cox_results_nested(results_dict, covariate):\n",
    "    aggregated_results = {}\n",
    "    for organ, disease_results in results_dict.items():\n",
    "        aggregated_data = {\n",
    "            'Disease': [],\n",
    "            'HR': [],\n",
    "            'CI_lower': [],\n",
    "            'CI_upper': [],\n",
    "            'p': [],\n",
    "            'Events': []\n",
    "        }\n",
    "        \n",
    "        for disease, content in disease_results.items():\n",
    "            if isinstance(content, dict):\n",
    "                summary = content.get('summary')\n",
    "                model = content.get('model')\n",
    "                \n",
    "                if isinstance(summary, pd.DataFrame):\n",
    "                    if covariate in summary.index:\n",
    "                        hr = summary.loc[covariate, 'exp(coef)']\n",
    "                        ci_lower = summary.loc[covariate, 'exp(coef) lower 95%']\n",
    "                        ci_upper = summary.loc[covariate, 'exp(coef) upper 95%']\n",
    "                        p_val = summary.loc[covariate, 'p']\n",
    "                        \n",
    "                        # Extract number of events from the model (if available)\n",
    "                        if model is not None and hasattr(model, 'event_observed'):\n",
    "                            events = model.event_observed.sum()\n",
    "                        else:\n",
    "                            events = 'N/A'\n",
    "                        \n",
    "                        aggregated_data['Disease'].append(disease)\n",
    "                        aggregated_data['HR'].append(hr)\n",
    "                        aggregated_data['CI_lower'].append(ci_lower)\n",
    "                        aggregated_data['CI_upper'].append(ci_upper)\n",
    "                        aggregated_data['p'].append(p_val)\n",
    "                        aggregated_data['Events'].append(events)\n",
    "                    else:\n",
    "                        print(f\"Covariate '{covariate}' not found in summary for disease '{disease}' in organ '{organ}'. Skipping.\")\n",
    "                else:\n",
    "                    print(f\"Summary for disease '{disease}' in organ '{organ}' is not a DataFrame. Skipping.\")\n",
    "            else:\n",
    "                print(f\"Disease '{disease}' in organ '{organ}' has content of type {type(content)}. Skipping.\")\n",
    "        \n",
    "        summary_df = pd.DataFrame(aggregated_data)\n",
    "        \n",
    "        if not summary_df.empty:\n",
    "            # Perform FDR correction using Benjamini-Hochberg on the p-values for this organ\n",
    "            reject, fdr_corrected, _, _ = multipletests(summary_df['p'], method='fdr_bh')\n",
    "            summary_df['FDR'] = fdr_corrected\n",
    "        else:\n",
    "            summary_df['FDR'] = []\n",
    "        \n",
    "        aggregated_results[organ] = summary_df\n",
    "        \n",
    "    return aggregated_results\n",
    "\n",
    "\n",
    "def plot_forest_plot_with_annotations_nested(aggregated_results, covariate='age_gap_measuredprot', title_prefix='Forest Plot for'):\n",
    "    for organ, summary_df in aggregated_results.items():\n",
    "        summary_df = summary_df.sort_values(by='HR', ascending=True)\n",
    "        y_positions = np.arange(len(summary_df))\n",
    "        \n",
    "        # Determine marker styles based on FDR\n",
    "        # Solid blue dot if FDR < 0.05, else unfilled blue circle\n",
    "        facecolors = ['blue' if fdr < 0.05 else 'none' for fdr in summary_df['FDR']]\n",
    "        edgecolors = ['blue' for _ in summary_df['FDR']]\n",
    "        \n",
    "        fig, ax1 = plt.subplots(figsize=(14, 0.6 * len(summary_df) + 3))\n",
    "        \n",
    "        # Plot error bars (95CI)\n",
    "        ax1.errorbar(\n",
    "            summary_df['HR'],\n",
    "            y_positions,\n",
    "            xerr=[summary_df['HR'] - summary_df['CI_lower'], summary_df['CI_upper'] - summary_df['HR']],\n",
    "            fmt='none',\n",
    "            ecolor='black',\n",
    "            elinewidth=1,\n",
    "            capsize=3\n",
    "        )\n",
    "        \n",
    "        # Plot HR points without overriding facecolors\n",
    "        scatter = ax1.scatter(\n",
    "            summary_df['HR'],\n",
    "            y_positions,\n",
    "            edgecolors=edgecolors,\n",
    "            facecolors=facecolors,\n",
    "            marker='o',\n",
    "            s=100,\n",
    "            linewidth=1\n",
    "        )\n",
    "\n",
    "        ax1.axvline(x=1, color='red', linestyle='--')\n",
    "        ax1.set_yticks(y_positions)\n",
    "        ax1.set_yticklabels(summary_df['Disease'])\n",
    "        ax1.set_xlabel('Hazard Ratio (HR)')\n",
    "        ax1.set_title(f'{title_prefix} {organ.capitalize()}')\n",
    "        x_max = summary_df['CI_upper'].max()\n",
    "        x_min = summary_df['CI_lower'].min()\n",
    "        x_buffer = (x_max - x_min) * 0.2\n",
    "        ax1.set_xlim(x_min - x_buffer, x_max + x_buffer)\n",
    "        ax1.grid(False)\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.set_ylim(ax1.get_ylim())\n",
    "        ax2.set_yticks(y_positions)\n",
    "        ax2.set_yticklabels(summary_df['Events'])\n",
    "        ax2.set_ylabel('Number of Events')\n",
    "        ax2.spines['right'].set_visible(False)\n",
    "        ax2.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "        ax2.yaxis.set_label_position(\"right\")\n",
    "        ax2.yaxis.tick_right()\n",
    "        ax2.grid(False)\n",
    "        \n",
    "        solid_patch = mpatches.Patch(facecolor='blue', edgecolor='blue', label='FDR < 0.05')\n",
    "        hollow_patch = mpatches.Patch(facecolor='none', edgecolor='blue', label='FDR ≥ 0.05')\n",
    "        plt.legend(handles=[solid_patch, hollow_patch], loc='upper left')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9726d38e-df36-4652-927d-583eb15fa573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read censor date dataframe, varies by nationality\n",
    "censor_date_df = pd.read_csv('/path/to/censor/df')\n",
    "censor_date_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030d98b0-0c82-4f48-b855-573838692635",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# covariates to include\n",
    "covariate_columns = ['age_gap_measuredprot_zscore', 'sex', 'actual_age']\n",
    "categorical_covariates = ['sex']\n",
    "\n",
    "# default censor (latest followup date across omop)\n",
    "default_censor_date = '2022-12-31'\n",
    "\n",
    "\n",
    "disease_columns = [col for col in master_label.columns if col != 'person_id']\n",
    "\n",
    "results_measuredprot, merged_dfs = perform_multiple_cox_models_individual_censor_dates(\n",
    "    covdf_dict=covariates_dfs,\n",
    "    target_df=master_label,\n",
    "    agedf=age_df,\n",
    "    disease_columns=disease_columns,\n",
    "    covariate_columns=covariate_columns,\n",
    "    categorical_covariates=categorical_covariates,\n",
    "    censor_date_df=censor_date_df,  \n",
    "    default_censor_date=default_censor_date,\n",
    "    date_format='%Y-%m-%d'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a9fe83-1cb5-4fa0-8b69-7ce21a9d8892",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# covariates to include\n",
    "covariate_columns = ['age_gap_rabit_zscore', 'sex', 'actual_age']\n",
    "categorical_covariates = ['sex']\n",
    "\n",
    "# default censor (latest followup date across omop)\n",
    "default_censor_date = '2022-12-31'\n",
    "\n",
    "\n",
    "disease_columns = [col for col in master_label.columns if col != 'person_id']\n",
    "\n",
    "results_rabit, merged_dfs = perform_multiple_cox_models_individual_censor_dates(\n",
    "    covdf_dict=covariates_dfs,  \n",
    "    target_df=master_label,\n",
    "    agedf=age_df,\n",
    "    disease_columns=disease_columns,\n",
    "    covariate_columns=covariate_columns,\n",
    "    categorical_covariates=categorical_covariates,\n",
    "    censor_date_df=censor_date_df,    \n",
    "    default_censor_date=default_censor_date,\n",
    "    date_format='%Y-%m-%d'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70340ba-cbd4-492b-8e73-91f2195ec705",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# covariates to include\n",
    "covariate_columns = ['age_gap_ehr_zscore', 'sex', 'actual_age']\n",
    "categorical_covariates = ['sex']\n",
    "\n",
    "# default censor (latest followup date across omop)\n",
    "default_censor_date = '2022-12-31'\n",
    "\n",
    "\n",
    "disease_columns = [col for col in master_label.columns if col != 'person_id']\n",
    "\n",
    "\n",
    "results_ehr, merged_dfs = perform_multiple_cox_models_individual_censor_dates(\n",
    "    covdf_dict=covariates_dfs,      # Dictionary of organ-specific covariate DataFrames\n",
    "    target_df=master_label,\n",
    "    agedf=age_df,\n",
    "    disease_columns=disease_columns,\n",
    "    covariate_columns=covariate_columns,\n",
    "    categorical_covariates=categorical_covariates,\n",
    "    censor_date_df=None,\n",
    "    default_censor_date=default_censor_date,\n",
    "    date_format='%Y-%m-%d'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bba3f0d-a1a6-448a-bd04-da067c37490c",
   "metadata": {},
   "source": [
    "# Visualize forest plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b8259d-92cf-41e7-8734-193a2d1c3d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forest_plots_grid(\n",
    "    aggregated_results_list: Sequence[Dict[str, pd.DataFrame]],\n",
    "    covariates: Sequence[str],\n",
    "    *,\n",
    "    title_prefix: str = '',\n",
    "    plot_ground_truth: bool = False,\n",
    "    ground_truth_path: str | None = None,\n",
    "    order_by: str = 'ground_truth',\n",
    "    exclude_covariates: Optional[Iterable[str]] = None,\n",
    "    ncols: int = 2,\n",
    "\n",
    "    # Label maps\n",
    "    label_replacements: dict | None = None,\n",
    "    covariate_label_map: dict | None = None,\n",
    "\n",
    "    # ---- COLOR / STYLE CONTROL ----\n",
    "    cov_colors: Dict[str, str] | Sequence[str] | None = None,  # map or list aligned with covariates\n",
    "    gt_color: str = \"black\",\n",
    "    dotted_line_color: str = \"#5d6778\",\n",
    "    sig_edgecolor: str = \"black\",\n",
    "    nonsig_face: str = \"none\",\n",
    "    ci_linewidth: float = 1.0,\n",
    "    ci_capsize: float = 3.0,\n",
    "    point_size: float = 100,\n",
    "\n",
    "    # Text sizes\n",
    "    title_fontsize: float = 16,\n",
    "    axis_label_fontsize: float = 14,\n",
    "    tick_label_fontsize: float = 12,\n",
    "    events_label_fontsize: float = 10,\n",
    "    legend_fontsize: float = 12,\n",
    "\n",
    "    # Right-hand events axis tweaks\n",
    "    events_tick_rotation: int = 90,\n",
    "    events_tick_pad: int = 6,\n",
    "\n",
    "    # Spacing between subplots\n",
    "    subplot_wspace: float = 0.45,\n",
    "    subplot_hspace: float = 0.4,\n",
    "\n",
    "    # Legend figure options\n",
    "    make_legend_figure: bool = True,\n",
    "    legend_title: str = \"Legend\",\n",
    "    legend_box_face: str = \"white\",\n",
    "    legend_box_edge: str = \"#000000\",\n",
    "    legend_save_path: Optional[str] = None,\n",
    "    legend_figsize: Tuple[float, float] = (4, 0),  # (width, height); height auto if 0\n",
    "):\n",
    "\n",
    "    # select covariates\n",
    "    if exclude_covariates:\n",
    "        excl = set([exclude_covariates] if isinstance(exclude_covariates, str) else exclude_covariates)\n",
    "        keep = [(cv, ag) for cv, ag in zip(covariates, aggregated_results_list) if cv not in excl]\n",
    "        if not keep:\n",
    "            raise ValueError(\"All covariates excluded.\")\n",
    "        covariates, aggregated_results_list = zip(*keep)\n",
    "\n",
    "    # load ground truth\n",
    "    if plot_ground_truth:\n",
    "        gt_df = pd.read_csv(ground_truth_path)\n",
    "\n",
    "    label_replacements = label_replacements or {}\n",
    "    covariate_label_map = covariate_label_map or {}\n",
    "\n",
    "    # colors\n",
    "    default_palette = ['#1f77b4', '#ff7f0e', '#2ca02c', '#9467bd',\n",
    "                       '#8c564b', '#17becf', '#e377c2', '#7f7f7f']\n",
    "    if cov_colors is None:\n",
    "        colors = default_palette[:len(covariates)]\n",
    "    elif isinstance(cov_colors, dict):\n",
    "        colors = [cov_colors.get(cv, default_palette[i % len(default_palette)])\n",
    "                  for i, cv in enumerate(covariates)]\n",
    "    else:\n",
    "        if len(cov_colors) < len(covariates):\n",
    "            raise ValueError(\"need more colors.\")\n",
    "        colors = list(cov_colors[:len(covariates)])\n",
    "\n",
    "    cov_handles = [\n",
    "        Line2D([], [], marker='o', color='w',\n",
    "               markerfacecolor=colors[i], markeredgecolor=colors[i],\n",
    "               markersize=8,\n",
    "               label=covariate_label_map.get(covariates[i], covariates[i]))\n",
    "        for i in range(len(covariates))\n",
    "    ]\n",
    "    sig_handles = [\n",
    "        Line2D([], [], marker='o', color=sig_edgecolor, markerfacecolor=sig_edgecolor,\n",
    "               markersize=8, label='FDR < 0.05'),\n",
    "        Line2D([], [], marker='o', color=sig_edgecolor, markerfacecolor='none',\n",
    "               markersize=8, label='FDR ≥ 0.05'),\n",
    "    ]\n",
    "    if plot_ground_truth:\n",
    "        cov_handles.append(\n",
    "            Line2D([], [], marker='D', color=gt_color, markersize=8, label='Ground Truth')\n",
    "        )\n",
    "\n",
    "    organs = list(aggregated_results_list[0].keys())\n",
    "    nplots = len(organs)\n",
    "    nrows = math.ceil(nplots / ncols)\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows, ncols,\n",
    "        figsize=(7 * ncols, 8 * len(organs) / ncols + 3 * nrows),\n",
    "        squeeze=False\n",
    "    )\n",
    "    axes_flat = axes.flatten()\n",
    "    fig.subplots_adjust(wspace=subplot_wspace, hspace=subplot_hspace)\n",
    "\n",
    "    for idx, organ in enumerate(organs):\n",
    "        ax = axes_flat[idx]\n",
    "\n",
    "        # determine order\n",
    "        if order_by == 'ground_truth':\n",
    "            gt_sub = gt_df[gt_df['organ'] == organ]\n",
    "            df0 = aggregated_results_list[0][organ].copy()\n",
    "            df0['clean'] = df0['Disease'].str.replace('_earliest', '', regex=False)\n",
    "            merged = df0.merge(gt_sub, left_on='clean', right_on='trait', how='left')\n",
    "            merged['exp(coef)'].fillna(-np.inf, inplace=True)\n",
    "            order = merged.sort_values('exp(coef)', ascending=False)['Disease']\n",
    "        else:\n",
    "            idx_cov = covariates.index(order_by)\n",
    "            order = aggregated_results_list[idx_cov][organ] \\\n",
    "                        .sort_values('HR', ascending=False)['Disease']\n",
    "        disease_order = order.tolist()\n",
    "        base_y = np.arange(len(disease_order))\n",
    "\n",
    "        plot_dfs = [\n",
    "            agr[organ].set_index('Disease').loc[disease_order].reset_index()\n",
    "            for agr in aggregated_results_list\n",
    "        ]\n",
    "\n",
    "        # x limits\n",
    "        x_min = min(df['CI_lower'].min() for df in plot_dfs)\n",
    "        x_max = max(df['CI_upper'].max() for df in plot_dfs)\n",
    "        pad = (x_max - x_min) * 0.2\n",
    "\n",
    "        # plot each covariate series\n",
    "        offset = 0.3\n",
    "        for i, df in enumerate(plot_dfs):\n",
    "            dy = (i - (len(plot_dfs) - 1) / 2) * offset\n",
    "            yy = base_y + dy\n",
    "            col = colors[i]\n",
    "\n",
    "            ax.errorbar(\n",
    "                df['HR'], yy,\n",
    "                xerr=[df['HR'] - df['CI_lower'], df['CI_upper'] - df['HR']],\n",
    "                fmt='none', ecolor=col, elinewidth=ci_linewidth, capsize=ci_capsize\n",
    "            )\n",
    "            faces = [col if p < 0.05 else nonsig_face for p in df['FDR']]\n",
    "            ax.scatter(\n",
    "                df['HR'], yy, s=point_size, marker='o',\n",
    "                facecolor=faces, edgecolor=col,\n",
    "                linewidth=1, zorder=3\n",
    "            )\n",
    "\n",
    "        # overlay ground truth\n",
    "        if plot_ground_truth:\n",
    "            gt_map = gt_df[gt_df['organ'] == organ].set_index('trait')\n",
    "            for j, dis in enumerate(disease_order):\n",
    "                clean = dis.replace('_earliest', '')\n",
    "                if clean in gt_map.index:\n",
    "                    r = gt_map.loc[clean]\n",
    "                    ax.errorbar(\n",
    "                        r['exp(coef)'], base_y[j],\n",
    "                        xerr=[[r['exp(coef)'] - r['exp(coef) lower 95%']],\n",
    "                              [r['exp(coef) upper 95%'] - r['exp(coef)']]],\n",
    "                        fmt='none', ecolor=gt_color, elinewidth=ci_linewidth, capsize=ci_capsize\n",
    "                    )\n",
    "                    ax.scatter(\n",
    "                        r['exp(coef)'], base_y[j], s=point_size,\n",
    "                        marker='D', color=gt_color, zorder=4\n",
    "                    )\n",
    "\n",
    "        # format axes\n",
    "        ax.axvline(1, color=dotted_line_color, linestyle='--')  # dotted ref line\n",
    "        labels = [label_replacements.get(d, d) for d in disease_order]\n",
    "        ax.set_yticks(base_y)\n",
    "        ax.set_yticklabels(labels, fontsize=tick_label_fontsize)\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_xlabel('Hazard Ratio (HR)', fontsize=axis_label_fontsize)\n",
    "        title = f\"{title_prefix} {organ.capitalize()}\" if title_prefix else organ.capitalize()\n",
    "        ax.set_title(title, fontsize=title_fontsize)\n",
    "        ax.set_xlim(x_min - pad, x_max + pad)\n",
    "        ax.tick_params(axis='x', labelsize=tick_label_fontsize)\n",
    "\n",
    "        # remove grid lines\n",
    "        ax.grid(False)\n",
    "\n",
    "        # right-hand events axis\n",
    "        events = (\n",
    "            aggregated_results_list[0][organ]\n",
    "            .set_index('Disease')\n",
    "            .loc[disease_order]['Events']\n",
    "            .tolist()\n",
    "        )\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.patch.set_visible(False)\n",
    "        ax2.set_zorder(ax.get_zorder() - 1)\n",
    "        ax2.set_ylim(ax.get_ylim())\n",
    "        ax2.set_yticks(base_y)\n",
    "        ax2.set_yticklabels(events,\n",
    "                            fontsize=events_label_fontsize,\n",
    "                            rotation=events_tick_rotation,\n",
    "                            va=\"center\",\n",
    "                            ha=\"left\")\n",
    "        ax2.tick_params(axis='y', pad=events_tick_pad)\n",
    "        # ax2.set_ylabel('Number of Events', fontsize=axis_label_fontsize)\n",
    "        ax2.spines['right'].set_visible(False)\n",
    "        ax2.tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "        ax2.grid(False)\n",
    "\n",
    "    # delete unused panels\n",
    "    for j in range(nplots, nrows * ncols):\n",
    "        fig.delaxes(axes_flat[j])\n",
    "\n",
    "    # separate legend figure\n",
    "    legend_fig = None\n",
    "    if make_legend_figure:\n",
    "        handles = cov_handles + sig_handles\n",
    "        if legend_figsize[1] == 0:\n",
    "            est_h = max(2, 0.55 * len(handles) + 0.5)\n",
    "            legend_figsize = (legend_figsize[0], est_h)\n",
    "\n",
    "        legend_fig, legend_ax = plt.subplots(figsize=legend_figsize)\n",
    "        legend_ax.axis(\"off\")\n",
    "        leg = legend_ax.legend(\n",
    "            handles=handles,\n",
    "            loc='center',\n",
    "            ncol=1,\n",
    "            frameon=True,\n",
    "            fontsize=legend_fontsize,\n",
    "            title=legend_title,\n",
    "            title_fontsize=axis_label_fontsize\n",
    "        )\n",
    "        frame = leg.get_frame()\n",
    "        frame.set_facecolor(legend_box_face)\n",
    "        frame.set_edgecolor(legend_box_edge)\n",
    "\n",
    "        legend_fig.tight_layout()\n",
    "        if legend_save_path:\n",
    "            import os\n",
    "            os.makedirs(os.path.dirname(legend_save_path) or \".\", exist_ok=True)\n",
    "            legend_fig.savefig(legend_save_path, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "    return fig, axes, legend_fig\n",
    "\n",
    "\n",
    "\n",
    "aggregated_results_measuredprot = aggregate_cox_results_nested(results_measuredprot, covariate='age_gap_measuredprot_zscore')\n",
    "aggregated_results_rabit = aggregate_cox_results_nested(results_rabit, covariate='age_gap_rabit_zscore')\n",
    "aggregated_results_ehr = aggregate_cox_results_nested(results_ehr, covariate='age_gap_ehr_zscore')\n",
    "\n",
    "\n",
    "label_replacements = {\n",
    "    'Parkinson_disease_and_parkinsonism_earliest': 'PD',\n",
    "    'Alzheimer_disease_earliest':  'AD',\n",
    "    'Chronic_liver_disease_earliest': 'CLD',\n",
    "    'Ischemic_heart_disease_earliest': 'IHD',\n",
    "    'Osteoporosis_earliest': 'OSP',\n",
    "    'Emphysema_COPD_earliest': 'COPD',\n",
    "    'Type2_diabetes_earliest': 'T2DM',\n",
    "    'Chronic_kidney_disease_earliest': 'CKD',\n",
    "    'Leukemia': 'Leukemia',\n",
    "    'Non-Hodgkin_lymphoma': 'NHL',\n",
    "    'Cerebrovascular_disease_earliest': 'CBVD',\n",
    "    'Osteoarthritis_earliest': 'OA',\n",
    "    'Rheumatoid_arthritis_earliest': 'RA',\n",
    "    'All_cause_dementia_earliest': 'Dementia',\n",
    "    'Heart_failure_earliest': 'HF',\n",
    "    'Atrial_fibrillation_or_flutter_earliest': 'AFib',\n",
    "    'Vascular_dementia_earliest': 'VD'\n",
    "}\n",
    "\n",
    "\n",
    "covariate_label_map = {\n",
    "    'age_gap_measuredprot_zscore': 'Measured Protein Age Gap',\n",
    "    'age_gap_rabit_zscore':  'RABIT Protein Age Gap',\n",
    "    'age_gap_ehr_zscore':    'EHR Age Gap',\n",
    "}\n",
    "\n",
    "plot_forest_plots_grid(\n",
    "    aggregated_results_list=[aggregated_results_measuredprot,\n",
    "                             aggregated_results_rabit,\n",
    "                             aggregated_results_ehr],\n",
    "    covariates=['age_gap_measuredprot_zscore',\n",
    "                'age_gap_rabit_zscore',\n",
    "                'age_gap_ehr_zscore'],\n",
    "    plot_ground_truth=True,\n",
    "    ground_truth_path='/ground/truth/dataframe/from/original/paper',\n",
    "    order_by='age_gap_rabit_zscore',\n",
    "    ncols=4,\n",
    "    label_replacements=label_replacements,\n",
    "    covariate_label_map=covariate_label_map,\n",
    "    cov_colors={\n",
    "        'age_gap_measuredprot_zscore': '#d89a97',\n",
    "        'age_gap_rabit_zscore':  '#94bed8',\n",
    "        'age_gap_ehr_zscore':    '#ead490',\n",
    "    },\n",
    "    gt_color='#5d6778',\n",
    "    title_fontsize=18,\n",
    "    axis_label_fontsize=16,\n",
    "    tick_label_fontsize=14,\n",
    "    events_label_fontsize=12,\n",
    "    legend_fontsize=14,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5302178-4761-418c-ab3c-1e3a89b8afc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def dict_to_hr_dataframe(nested_results_dict, disease_col='Disease'):\n",
    "    rows = []\n",
    "    for organ, df in nested_results_dict.items():\n",
    "        required = [disease_col, 'HR', 'FDR']\n",
    "        temp = df[required].copy()\n",
    "        temp['Organ'] = organ\n",
    "        rows.append(temp)\n",
    "    if rows:\n",
    "        return pd.concat(rows, ignore_index=True)\n",
    "\n",
    "    return pd.DataFrame(columns=['Organ', disease_col, 'HR', 'FDR'])\n",
    "\n",
    "def plot_hr_scatter_nested_per_organ(df1, df2, disease_col='Disease', hr_col1='HR', hr_col2='HR', \n",
    "                                     title_prefix=\"Hazard Ratios Comparison for\", \n",
    "                                     df1label='rabit', df2label='measuredprot'):\n",
    "    # Determine the set of common organs\n",
    "    organs1 = set(df1['Organ'].unique())\n",
    "    organs2 = set(df2['Organ'].unique())\n",
    "    common_organs = organs1.intersection(organs2)\n",
    "    \n",
    "    if not common_organs:\n",
    "        print(\"No common organs.\")\n",
    "        return\n",
    "\n",
    "    for organ in sorted(common_organs):\n",
    "        # Filter the DataFrames for the current organ\n",
    "        df1_sub = df1[df1['Organ'] == organ]\n",
    "        df2_sub = df2[df2['Organ'] == organ]\n",
    "        merge_cols = [disease_col]\n",
    "        merged_df = pd.merge(df1_sub, df2_sub, on=merge_cols, suffixes=('_1', '_2'))      \n",
    "        # Calculate correlations\n",
    "        try:\n",
    "            pearson_corr, pearson_p = pearsonr(merged_df[f\"{hr_col1}_1\"], merged_df[f\"{hr_col2}_2\"])\n",
    "            spearman_corr, spearman_p = spearmanr(merged_df[f\"{hr_col1}_1\"], merged_df[f\"{hr_col2}_2\"])\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating correlations for organ {organ}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Compute best-fit linear regression\n",
    "        try:\n",
    "            reg_results = linregress(merged_df[f\"{hr_col1}_1\"], merged_df[f\"{hr_col2}_2\"])\n",
    "            slope, intercept, r_value, p_value, std_err = reg_results\n",
    "            r2 = r_value**2\n",
    "        except Exception as e:\n",
    "            print(f\"Error in linear regression for organ {organ}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Create scatter plot for this organ\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        \n",
    "        # Plot each point individually according to its FDR values.\n",
    "        for idx, row in merged_df.iterrows():\n",
    "            x_val = row[f\"{hr_col1}_1\"]\n",
    "            y_val = row[f\"{hr_col2}_2\"]\n",
    "            fdr1 = row['FDR_1']\n",
    "            fdr2 = row['FDR_2']\n",
    "            \n",
    "            # Decide marker appearance based on FDR thresholds\n",
    "            if fdr1 < 0.05 and fdr2 >= 0.05:\n",
    "                facecolor = 'red'\n",
    "                edgecolor = None\n",
    "            elif fdr2 < 0.05 and fdr1 >= 0.05:\n",
    "                facecolor = 'blue'\n",
    "                edgecolor = None\n",
    "            elif fdr1 < 0.05 and fdr2 < 0.05:\n",
    "                facecolor = 'purple'\n",
    "                edgecolor = None\n",
    "            else:\n",
    "                facecolor = 'white'\n",
    "                edgecolor = 'black'\n",
    "            plt.scatter(x_val, y_val, color=facecolor, edgecolor=edgecolor, s=50, zorder=3, marker='o')\n",
    "        \n",
    "        # Plot best-fit line\n",
    "        x_min = merged_df[f\"{hr_col1}_1\"].min()\n",
    "        x_max = merged_df[f\"{hr_col1}_1\"].max()\n",
    "        x_vals = [x_min, x_max]\n",
    "        y_vals = [slope * x + intercept for x in x_vals]\n",
    "        plt.plot(x_vals, y_vals, 'g-', zorder=2)  # (No legend label here)\n",
    "        \n",
    "        # Annotate each point with the disease name\n",
    "        texts = []\n",
    "        for index, row in merged_df.iterrows():\n",
    "            label = row[disease_col]\n",
    "            txt = plt.text(row[f\"{hr_col1}_1\"], row[f\"{hr_col2}_2\"], label, \n",
    "                           fontsize=9, ha='right', va='bottom', zorder=4)\n",
    "            texts.append(txt)\n",
    "        \n",
    "        # Adjust text to reduce overlap\n",
    "        adjust_text(texts, only_move={'points': 'y', 'text': 'y'},\n",
    "                    arrowprops=dict(arrowstyle=\"->\", color='gray', lw=0.5))\n",
    "        \n",
    "        # Set labels and title\n",
    "        plt.xlabel(f\"Hazard Ratio from {df1label} ({hr_col1})\")\n",
    "        plt.ylabel(f\"Hazard Ratio from {df2label} ({hr_col2})\")\n",
    "        plt.title(f\"{title_prefix} {organ.capitalize()}\")\n",
    "        \n",
    "        # Annotate correlation statistics in the upper left\n",
    "        legend_text = (\n",
    "            f\"Pearson r = {pearson_corr:.3f} (p = {pearson_p:.3g})\\n\"\n",
    "            f\"Spearman r = {spearman_corr:.3f} (p = {spearman_p:.3g})\"\n",
    "        )\n",
    "        plt.text(0.05, 0.95, legend_text, transform=plt.gca().transAxes, fontsize=10,\n",
    "                 verticalalignment='top', bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.5))\n",
    "        \n",
    "        # Note: The legend is intentionally omitted from each scatter plot.\n",
    "        \n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # After all scatter plots have been displayed, create a separate legend figure.\n",
    "    figLegend = plt.figure(figsize=(4, 4))\n",
    "    axLegend = figLegend.add_subplot(111)\n",
    "    axLegend.axis('off')\n",
    "        custom_handles = [\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markeredgecolor='red', markersize=8,\n",
    "               label=f\"Significant in {df1label} only\"),\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markeredgecolor='blue', markersize=8,\n",
    "               label=f\"Significant in {df2label} only\"),\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor='purple', markeredgecolor='purple', markersize=8,\n",
    "               label=\"Significant in both\"),\n",
    "        Line2D([0], [0], marker='o', color='black', markerfacecolor='white', markersize=8,\n",
    "               label=\"Not significant in either\"),\n",
    "        Line2D([0], [0], color='g', lw=2, label=\"Best-fit line\")\n",
    "    ]\n",
    "    axLegend.legend(handles=custom_handles, loc='center', ncol=1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "df_rabit = dict_to_hr_dataframe(aggregated_results_rabit, disease_col='Disease')\n",
    "df_measuredprot = dict_to_hr_dataframe(aggregated_results_measuredprot, disease_col='Disease')\n",
    "df_ehr = dict_to_hr_dataframe(aggregated_results_ehr, disease_col='Disease')\n",
    "\n",
    "# Create separate scatter plots for each organ comparing the HRs from rabit vs. measuredprot.\n",
    "plot_hr_scatter_nested_per_organ(df_rabit, df_measuredprot, disease_col='Disease', hr_col1='HR', hr_col2='HR',\n",
    "                                 title_prefix=\"Hazard Ratios Comparison for\", \n",
    "                                 df1label='RABIT Proteomics', df2label='Measured Proteomics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6fd0e2-9ce8-4369-8024-d5f6dd572afe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def _benjamini_hochberg(pvals):\n",
    "    import numpy as np\n",
    "    p = np.asarray(pvals, dtype=float)\n",
    "    m = np.sum(~np.isnan(p))\n",
    "    if m == 0:\n",
    "        return [float(\"nan\")] * len(p)\n",
    "    idx = np.argsort(p)\n",
    "    ranks = np.arange(1, len(p) + 1)\n",
    "    non_nan = ~np.isnan(p[idx])\n",
    "    sp = p[idx][non_nan]\n",
    "    adj = sp * m / ranks[non_nan]\n",
    "    adj = np.minimum.accumulate(adj[::-1])[::-1]\n",
    "    full = np.full_like(p, np.nan)\n",
    "    full[idx[non_nan]] = np.clip(adj, 0, 1)\n",
    "    return full.tolist()\n",
    "\n",
    "def plot_hr_scatter_series(\n",
    "    df1, df2,\n",
    "    disease_col: str = \"Disease\",\n",
    "    hr_col1: str = \"HR\",\n",
    "    hr_col2: str = \"HR\",\n",
    "    df1label: str = \"rabit\",\n",
    "    df2label: str = \"measuredprot\",\n",
    "    label_replacements: dict | None = None,\n",
    "    title_fontsize: float = 16,\n",
    "    axis_label_fontsize: float = 14,\n",
    "    tick_label_fontsize: float = 12,\n",
    "    dot_label_fontsize: float = 10,\n",
    "    corr_label_fontsize: float = 12,\n",
    "    legend_fontsize: float = 12,\n",
    "    invert: bool = False,\n",
    "\n",
    "    color_df1_only: str = \"#d62728\",   # significant only in df1\n",
    "    color_df2_only: str = \"#1f77b4\",   # significant only in df2\n",
    "    color_both:     str = \"#9467bd\",   # significant in both\n",
    "    color_nonsig_face: str = \"white\",  # non-sig fill\n",
    "    color_nonsig_edge: str = \"black\",  # non-sig edge\n",
    "    line_color: str = \"#2ca02c\",       # best-fit line\n",
    "):\n",
    "    label_replacements = label_replacements or {}\n",
    "\n",
    "    # common organs\n",
    "    organs = sorted(set(df1[\"Organ\"]) & set(df2[\"Organ\"]))\n",
    "    if not organs:\n",
    "        raise ValueError(\"No common organs to plot.\")\n",
    "\n",
    "    # pearson correlations\n",
    "    panels = []\n",
    "    for organ in organs:\n",
    "        m1 = df1[df1[\"Organ\"] == organ]\n",
    "        m2 = df2[df2[\"Organ\"] == organ]\n",
    "        merged = pd.merge(m1, m2, on=[disease_col], suffixes=(\"_1\", \"_2\"))\n",
    "        if merged.empty:\n",
    "            continue\n",
    "        r, p_raw = pearsonr(merged[f\"{hr_col1}_1\"], merged[f\"{hr_col2}_2\"])\n",
    "        panels.append({\"organ\": organ, \"df\": merged, \"r\": r, \"p_raw\": p_raw})\n",
    "\n",
    "    # adjust p values with benjamini hochberg\n",
    "    p_bh_list = _benjamini_hochberg([p[\"p_raw\"] for p in panels])\n",
    "    for panel, bh in zip(panels, p_bh_list):\n",
    "        panel[\"p_bh\"] = bh\n",
    "\n",
    "    for panel in panels:\n",
    "        organ  = panel[\"organ\"]\n",
    "        merged = panel[\"df\"]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "        x_vals, y_vals, labels = [], [], []\n",
    "        for _, row in merged.iterrows():\n",
    "            xi = row[f\"{hr_col2}_2\"] if invert else row[f\"{hr_col1}_1\"]\n",
    "            yi = row[f\"{hr_col1}_1\"] if invert else row[f\"{hr_col2}_2\"]\n",
    "            f1, f2 = row[\"FDR_1\"], row[\"FDR_2\"]\n",
    "\n",
    "            if f1 < 0.05 <= f2:\n",
    "                fc, ec = color_df1_only, None\n",
    "            elif f2 < 0.05 <= f1:\n",
    "                fc, ec = color_df2_only, None\n",
    "            elif f1 < 0.05 and f2 < 0.05:\n",
    "                fc, ec = color_both, None\n",
    "            else:\n",
    "                fc, ec = color_nonsig_face, color_nonsig_edge\n",
    "\n",
    "            ax.scatter(xi, yi, facecolor=fc, edgecolor=ec, s=60, zorder=3)\n",
    "            x_vals.append(xi); y_vals.append(yi)\n",
    "            labels.append(label_replacements.get(row[disease_col], row[disease_col]))\n",
    "\n",
    "        # best-fit line\n",
    "        slope, intercept, *_ = linregress(x_vals, y_vals)\n",
    "        x0, x1 = min(x_vals), max(x_vals)\n",
    "        ax.plot([x0, x1], [slope * x0 + intercept, slope * x1 + intercept],\n",
    "                color=line_color, zorder=2)\n",
    "\n",
    "        # labels\n",
    "        texts = []\n",
    "        for xv, yv, lab in zip(x_vals, y_vals, labels):\n",
    "            texts.append(ax.text(xv, yv, lab,\n",
    "                                 fontsize=dot_label_fontsize,\n",
    "                                 ha=\"center\", va=\"center\", zorder=4))\n",
    "        adjust_text(\n",
    "            texts, x=x_vals, y=y_vals, ax=ax,\n",
    "            arrowprops=dict(arrowstyle=\"->\", color=\"gray\", lw=0.5),\n",
    "            expand_points=(1.2, 1.2), expand_text=(1.2, 1.2),\n",
    "            force_points=(0.3, 0.3), force_text=(0.3, 0.3),\n",
    "            avoid_self=True\n",
    "        )\n",
    "\n",
    "        # titles / axis labels\n",
    "        ax.set_title(organ.capitalize(), fontsize=title_fontsize, pad=10)\n",
    "        if invert:\n",
    "            ax.set_xlabel(f\"{df2label} {hr_col2}\", fontsize=axis_label_fontsize, labelpad=8)\n",
    "            ax.set_ylabel(f\"{df1label} {hr_col1}\", fontsize=axis_label_fontsize, labelpad=8)\n",
    "        else:\n",
    "            ax.set_xlabel(f\"{df1label} {hr_col1}\", fontsize=axis_label_fontsize, labelpad=8)\n",
    "            ax.set_ylabel(f\"{df2label} {hr_col2}\", fontsize=axis_label_fontsize, labelpad=8)\n",
    "\n",
    "        ax.tick_params(labelsize=tick_label_fontsize)\n",
    "        ax.grid(False)\n",
    "\n",
    "        ax.text(\n",
    "            0.05, 0.95,\n",
    "            f\"r = {panel['r']:.3f}\\nBH-p = {panel['p_bh']:.2e}\",\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=corr_label_fontsize,\n",
    "            va=\"top\", ha=\"left\",\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8)\n",
    "        )\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # global legend\n",
    "    handles = [\n",
    "        Line2D([0], [0], marker=\"o\", color=\"w\", markerfacecolor=color_df1_only,\n",
    "               markersize=8, label=f\"Sig in {df1label} only\"),\n",
    "        Line2D([0], [0], marker=\"o\", color=\"w\", markerfacecolor=color_df2_only,\n",
    "               markersize=8, label=f\"Sig in {df2label} only\"),\n",
    "        Line2D([0], [0], marker=\"o\", color=\"w\", markerfacecolor=color_both,\n",
    "               markersize=8, label=\"Sig in both\"),\n",
    "        Line2D([0], [0], marker=\"o\", color=color_nonsig_edge, markerfacecolor=color_nonsig_face,\n",
    "               markersize=8, label=\"Not sig\"),\n",
    "        Line2D([0], [0], color=line_color, lw=2, label=\"Best-fit line\")\n",
    "    ]\n",
    "\n",
    "    fig_leg = plt.figure(figsize=(4, len(handles) * 0.7))\n",
    "    ax_leg = fig_leg.add_subplot(111)\n",
    "    ax_leg.axis(\"off\")\n",
    "    ax_leg.legend(handles=handles, loc=\"center\", ncol=1, frameon=False,\n",
    "                  fontsize=legend_fontsize)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_rabit = dict_to_hr_dataframe(aggregated_results_rabit, disease_col='Disease')\n",
    "df_measuredprot = dict_to_hr_dataframe(aggregated_results_measuredprot, disease_col='Disease')\n",
    "df_ehr = dict_to_hr_dataframe(aggregated_results_ehr, disease_col='Disease')\n",
    "\n",
    "label_replacements = {\n",
    "    'Parkinson_disease_and_parkinsonism_earliest': 'PD',\n",
    "    'Alzheimer_disease_earliest':  'AD',\n",
    "    'Chronic_liver_disease_earliest': 'CLD',\n",
    "    'Ischemic_heart_disease_earliest': 'IHD',\n",
    "    'Osteoporosis_earliest': 'OSP',\n",
    "    'Emphysema_COPD_earliest': 'COPD',\n",
    "    'Type2_diabetes_earliest': 'T2DM',\n",
    "    'Chronic_kidney_disease_earliest': 'CKD',\n",
    "    'Leukemia': 'Leukemia',\n",
    "    'Non-Hodgkin_lymphoma': 'NHL',\n",
    "    'Cerebrovascular_disease_earliest': 'CBVD',\n",
    "    'Osteoarthritis_earliest': 'OA',\n",
    "    'Rheumatoid_arthritis_earliest': 'RA',\n",
    "    'All_cause_dementia_earliest': 'Dementia',\n",
    "    'Heart_failure_earliest': 'HF',\n",
    "    'Atrial_fibrillation_or_flutter_earliest': 'AFib',\n",
    "    'Vascular_dementia_earliest': 'VD'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_hr_scatter_series(\n",
    "    df_rabit, df_measuredprot,\n",
    "    label_replacements=label_replacements,\n",
    "    df1label='RABIT Proteomics',\n",
    "    df2label='Measured Proteomics',\n",
    "    invert=True,\n",
    "    color_df1_only=\"#94bed8\",\n",
    "    color_df2_only=\"#d89a97\",\n",
    "    color_both=\"#a073a0\",\n",
    "    color_nonsig_face=\"#FFFFFF\",\n",
    "    color_nonsig_edge=\"#333333\",\n",
    "    line_color=\"#5D6778\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1233685-074b-4500-b282-67b39949d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_organ_correlation_scatter(\n",
    "    df1: pd.DataFrame,\n",
    "    df2: pd.DataFrame,\n",
    "    *,\n",
    "    disease_col: str = \"Disease\",\n",
    "    hr_col: str = \"HR\",\n",
    "    df1label: str = \"rabit\",\n",
    "    df2label: str = \"measuredprot\",\n",
    "    label_fontsize: int = 16,\n",
    "    save: bool = True,\n",
    "    out_dir: str | os.PathLike = (\n",
    "        \"/save/dir/\n",
    "    ),\n",
    "    filename: str | None = None,\n",
    "):\n",
    "    organs1 = set(df1[\"Organ\"])\n",
    "    organs2 = set(df2[\"Organ\"])\n",
    "    common_organs = organs1 & organs2\n",
    "    if not common_organs:\n",
    "        print(\"No common organs found.\")\n",
    "        return\n",
    "\n",
    "    rows = []\n",
    "    for organ in sorted(common_organs):\n",
    "        sub1 = df1[df1[\"Organ\"] == organ]\n",
    "        sub2 = df2[df2[\"Organ\"] == organ]\n",
    "        merged = pd.merge(sub1, sub2, on=disease_col, suffixes=(\"_1\", \"_2\"))\n",
    "        if merged.empty:\n",
    "            continue\n",
    "        try:\n",
    "            r_p, p_p = pearsonr(merged[f\"{hr_col}_1\"], merged[f\"{hr_col}_2\"])\n",
    "            r_s, _   = spearmanr(merged[f\"{hr_col}_1\"], merged[f\"{hr_col}_2\"])\n",
    "        except Exception:\n",
    "            continue\n",
    "        rows.append(\n",
    "            {\n",
    "                \"Organ\": organ,\n",
    "                \"Pearson_r\": r_p,\n",
    "                \"Pearson_p\": p_p,\n",
    "                \"Spearman_r\": r_s,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    if not rows:\n",
    "        print(\"No correlations computed.\")\n",
    "        return\n",
    "\n",
    "    res_df = pd.DataFrame(rows)\n",
    "    # BH correction\n",
    "    _, adj_p, _, _ = multipletests(res_df[\"Pearson_p\"], method=\"fdr_bh\")\n",
    "    res_df[\"Adj_P\"] = adj_p\n",
    "    res_df[\"neg_log10_adj_p\"] = -np.log10(res_df[\"Adj_P\"])\n",
    "    res_df[\"color\"] = res_df.apply(\n",
    "        lambda r: \"red\"\n",
    "        if (r[\"Pearson_r\"] >= 0.4 and r[\"Adj_P\"] < 0.05)\n",
    "        else \"grey\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    for _, row in res_df.iterrows():\n",
    "        ax.scatter(\n",
    "            row[\"Pearson_r\"],\n",
    "            row[\"neg_log10_adj_p\"],\n",
    "            s=100,\n",
    "            color=row[\"color\"],\n",
    "            edgecolor=\"k\",\n",
    "            zorder=3,\n",
    "        )\n",
    "\n",
    "    ax.axvline(0.4, color=\"blue\", linestyle=\":\", lw=1)\n",
    "    ax.axhline(-np.log10(0.05), color=\"blue\", linestyle=\":\", lw=1)\n",
    "\n",
    "    ax.set_xlabel(\"Pearson Correlation\")\n",
    "    ax.set_ylabel(\"-log10 BH-adjusted Pearson p-value\")\n",
    "    ax.set_title(f\"Organ System Correlations: {df1label} vs {df2label}\")\n",
    "    ax.grid(True)\n",
    "\n",
    "    # label\n",
    "    texts = [\n",
    "        ax.text(\n",
    "            row[\"Pearson_r\"],\n",
    "            row[\"neg_log10_adj_p\"],\n",
    "            row[\"Organ\"],\n",
    "            fontsize=label_fontsize,\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            zorder=4,\n",
    "        )\n",
    "        for _, row in res_df.iterrows()\n",
    "    ]\n",
    "    adjust_text(\n",
    "        texts,\n",
    "        expand_points=(2.5, 2.5),\n",
    "        expand_text=(2.5, 2.5),\n",
    "        force_text=(0.8, 0.8),\n",
    "        force_points=(0.6, 0.6),\n",
    "        arrowprops=dict(arrowstyle=\"->\", color=\"gray\", lw=0.5),\n",
    "        lim=200,\n",
    "    )\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        if filename is None:\n",
    "            filename = (\n",
    "                f\"organ_corr_{df1label}_vs_{df2label}.pdf\".replace(\" \", \"_\")\n",
    "            )\n",
    "        pdf_path = os.path.join(out_dir, filename)\n",
    "        fig.savefig(pdf_path, format=\"pdf\", bbox_inches=\"tight\")\n",
    "        print(f\"saved figure {pdf_path}\")\n",
    "\n",
    "    plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "plot_organ_correlation_scatter(df_rabit, df_measuredprot, disease_col='Disease', hr_col='HR',\n",
    "                               df1label='rabit', df2label='measuredprot', \n",
    "                               out_dir=\"/path/to/save\",\n",
    "                               filename='fig4b.pdf'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86902825-4c21-4385-ad3a-c2f7d51167ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ground truth\n",
    "gtruth = pd.read_csv('/path/to/ground/truth')\n",
    "gtruth_transformed = gtruth.rename(columns={\n",
    "    'organ': 'Organ',\n",
    "    'exp(coef)': 'HR',\n",
    "    'q': 'FDR'\n",
    "})\n",
    "\n",
    "# Create the 'Disease' column by appending '_earliest' to the values in 'trait'\n",
    "gtruth_transformed['Disease'] = gtruth_transformed['trait'] + '_earliest'\n",
    "\n",
    "# Keep only the necessary columns\n",
    "gtruth_transformed = gtruth_transformed[['Organ', 'Disease', 'HR', 'FDR']]\n",
    "\n",
    "plot_organ_correlation_scatter(gtruth_transformed, df_measuredprot, disease_col='Disease', hr_col='HR',\n",
    "                               df1label='Ground Truth', df2label='measuredprot',\n",
    "                               out_dir=\"/save/dir\",\n",
    "                               filename='fig4b.pdf')\n",
    "\n",
    "plot_organ_correlation_scatter(gtruth_transformed, df_rabit, disease_col='Disease', hr_col='HR',\n",
    "                               df1label='Ground Truth', df2label='rabit',\n",
    "                               out_dir=\"/save/dir\",\n",
    "                               filename='fig4b.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06500644-6074-45aa-8396-f4547617096e",
   "metadata": {},
   "source": [
    "# Young immune agers mortality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcac071d-fa1a-4d6f-9acc-8ae47ea4bcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "deathdf = pd.read_csv('/path/to/omop/death/table/death.csv')\n",
    "deathdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f2840e-02e8-4462-bed9-104e935d45dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "immune_age_gap_df = age_gap_simple_dfs['Immune']\n",
    "immune_age_gap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1403b835-01ed-4880-8438-b2b5afe1c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "death_dates   = (deathdf.loc[:, ['person_id', 'death_date']]\n",
    "                 .drop_duplicates(subset='person_id', keep='first'))\n",
    "prediction_ts = (age_df.loc[:, ['patient_id', 'prediction_time']]\n",
    "                 .drop_duplicates(subset='patient_id', keep='first'))\n",
    "merged = (immune_age_gap_df\n",
    "          .merge(death_dates,\n",
    "                 left_on='eid', right_on='person_id',\n",
    "                 how='left')\n",
    "          .drop(columns='person_id'))  \n",
    "merged = (merged\n",
    "          .merge(prediction_ts,\n",
    "                 left_on='eid', right_on='patient_id',\n",
    "                 how='left')\n",
    "          .drop(columns='patient_id'))\n",
    "\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff115bc-d80e-4d9a-a697-2ab39370bf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_km_by_quartile(\n",
    "    df: pd.DataFrame,\n",
    "    value_col: str,\n",
    "    *,\n",
    "    start_col: str = \"prediction_time\",\n",
    "    death_col: str = \"death_date\",\n",
    "    id_col: str = \"eid\",\n",
    "    censor_df: pd.DataFrame | None = None,\n",
    "    censor_id_col: str = \"patient_id\",\n",
    "    censor_date_col: str = \"censor_date\",\n",
    "    global_censor_date: str | pd.Timestamp | None = None,\n",
    "    title_prefix: str | None = None,\n",
    "    show_counts: bool = True,\n",
    "    show_ci: bool = True,\n",
    "    figsize: tuple[int, int] = (8, 6),\n",
    "    # ── NEW SAVING CONTROLS ────────────────────────────────────────────\n",
    "    save: bool = True,\n",
    "    out_dir: str | os.PathLike = (\n",
    "        \"/save/dir\"\n",
    "    ),\n",
    "    filename_prefix: str | None = None,   # e.g. \"km_age_gap\"\n",
    "):\n",
    "\n",
    "    cols = [id_col, value_col, start_col, death_col]\n",
    "    data = df.loc[:, cols].copy()\n",
    "\n",
    "    data[start_col] = pd.to_datetime(data[start_col], errors=\"coerce\")\n",
    "    data[death_col] = pd.to_datetime(data[death_col], errors=\"coerce\")\n",
    "    data = data.dropna(subset=[value_col, start_col])\n",
    "\n",
    "    if censor_df is not None:\n",
    "        censor_df = (\n",
    "            censor_df[[censor_id_col, censor_date_col]]\n",
    "            .drop_duplicates(subset=censor_id_col, keep=\"first\")\n",
    "        )\n",
    "        censor_df[censor_date_col] = pd.to_datetime(\n",
    "            censor_df[censor_date_col], errors=\"coerce\"\n",
    "        )\n",
    "        data = data.merge(\n",
    "            censor_df,\n",
    "            how=\"left\",\n",
    "            left_on=id_col,\n",
    "            right_on=censor_id_col,\n",
    "            validate=\"m:1\",\n",
    "        )\n",
    "    else:\n",
    "        data[censor_date_col] = pd.NaT\n",
    "\n",
    "    data[\"quartile\"] = pd.qcut(\n",
    "        data[value_col],\n",
    "        q=4,\n",
    "        labels=[\"Q1 (lowest)\", \"Q2\", \"Q3\", \"Q4 (highest)\"],\n",
    "    )\n",
    "\n",
    "    # censor using same individual censor dates from cox regression\n",
    "    if global_censor_date is None:\n",
    "        global_censor_date = data[death_col].max()\n",
    "        if pd.isna(global_censor_date):\n",
    "            global_censor_date = pd.Timestamp.today().normalize()\n",
    "    global_censor_date = pd.to_datetime(global_censor_date)\n",
    "\n",
    "    data[\"death_or_censor\"] = data[death_col]\n",
    "    mask_no_death = data[\"death_or_censor\"].isna()\n",
    "    data.loc[mask_no_death, \"death_or_censor\"] = data.loc[\n",
    "        mask_no_death, censor_date_col\n",
    "    ]\n",
    "    mask_still_na = data[\"death_or_censor\"].isna()\n",
    "    data.loc[mask_still_na, \"death_or_censor\"] = global_censor_date\n",
    "\n",
    "    data[\"event_observed\"] = data[death_col].notna()\n",
    "    data[\"duration\"] = (\n",
    "        data[\"death_or_censor\"] - data[start_col]\n",
    "    ).dt.days.clip(lower=0)\n",
    "\n",
    "    kmf = KaplanMeierFitter()\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    legend_entries = []  # (label, colour)\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "    for q, grp in data.groupby(\"quartile\", sort=False, observed=False):\n",
    "        label = f\"{q} (n={len(grp)})\" if show_counts else str(q)\n",
    "        kmf.fit(grp[\"duration\"], grp[\"event_observed\"], label=label)\n",
    "        kmf.plot(ci_show=show_ci, legend=False, ax=ax)\n",
    "\n",
    "        colour = ax.get_lines()[-1].get_color()\n",
    "        legend_entries.append((label, colour))\n",
    "\n",
    "    warnings.filterwarnings(\"default\", category=FutureWarning)\n",
    "\n",
    "    # statistical test for q1 and q4\n",
    "    q1_data = data[data[\"quartile\"] == \"Q1 (lowest)\"]\n",
    "    q4_data = data[data[\"quartile\"] == \"Q4 (highest)\"]\n",
    "\n",
    "    if not q1_data.empty and not q4_data.empty:\n",
    "        lr_res = logrank_test(\n",
    "            q1_data[\"duration\"],\n",
    "            q4_data[\"duration\"],\n",
    "            event_observed_A=q1_data[\"event_observed\"],\n",
    "            event_observed_B=q4_data[\"event_observed\"],\n",
    "        )\n",
    "        p_val = lr_res.p_value\n",
    "        print(f\"Log-rank test (Q1 vs Q4): p = {p_val:.3g}\")\n",
    "        ax.text(\n",
    "            0.03,\n",
    "            0.05,\n",
    "            f\"Q1 vs Q4 log-rank p = {p_val:.3g}\",\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=12,\n",
    "            va=\"bottom\",\n",
    "            ha=\"left\",\n",
    "            bbox=dict(facecolor=\"white\", alpha=0.6, edgecolor=\"none\"),\n",
    "        )\n",
    "    else:\n",
    "        p_val = np.nan\n",
    "        print(\"Q1 or Q4 group empty – p-value not computed.\")\n",
    "\n",
    "    # plot\n",
    "    title_bits = [title_prefix] if title_prefix else []\n",
    "    title_bits.append(f\"Survival by {value_col} quartiles\")\n",
    "    ax.set_title(\" – \".join(title_bits))\n",
    "    ax.set_xlabel(f\"Days from {start_col}\")\n",
    "    ax.set_ylabel(\"Survival probability\")\n",
    "\n",
    "    ax.tick_params(\n",
    "        axis=\"both\",\n",
    "        which=\"major\",\n",
    "        length=6,\n",
    "        width=1.2,\n",
    "        direction=\"out\",\n",
    "        bottom=True,\n",
    "        top=False,\n",
    "        left=True,\n",
    "        right=False,\n",
    "    )\n",
    "\n",
    "    fig.tight_layout()\n",
    "    leg_fig, leg_ax = plt.subplots(figsize=(4, 1))\n",
    "    leg_ax.axis(\"off\")\n",
    "    handles = [Line2D([0], [0], color=c, lw=2) for _, c in legend_entries]\n",
    "    labels = [lbl for lbl, _ in legend_entries]\n",
    "    leg_ax.legend(handles, labels, loc=\"center left\", frameon=False)\n",
    "    leg_fig.tight_layout()\n",
    "    if save:\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        if filename_prefix is None:\n",
    "            filename_prefix = f\"km_{value_col}\"\n",
    "\n",
    "        km_path = os.path.join(out_dir, f\"{filename_prefix}_km.pdf\")\n",
    "        leg_path = os.path.join(out_dir, f\"{filename_prefix}_legend.pdf\")\n",
    "\n",
    "        fig.savefig(km_path, format=\"pdf\", bbox_inches=\"tight\")\n",
    "        leg_fig.savefig(leg_path, format=\"pdf\", bbox_inches=\"tight\")\n",
    "        print(f\"KM plot saved   → {km_path}\")\n",
    "        print(f\"Legend saved    → {leg_path}\")\n",
    "\n",
    "    plt.show(fig)\n",
    "    plt.show(leg_fig)\n",
    "\n",
    "    return data, p_val\n",
    "\n",
    "\n",
    "\n",
    "plot_km_by_quartile(\n",
    "    merged,\n",
    "    value_col=\"age_gap_rabit_zscore\",\n",
    "    censor_df=censor_date_df,       \n",
    "    id_col=\"eid\",                 \n",
    "    censor_id_col=\"patient_id\",  \n",
    "    censor_date_col=\"censor_date\",\n",
    "    title_prefix=\"Immune cohort\",\n",
    "    out_dir=\"/save/dir\",   \n",
    "    filename_prefix=\"rabit_km\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b57176f-4cbd-4c03-b4b0-6c98b06f8246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "davidpython_updated",
   "language": "python",
   "name": "davidpython_updated"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
